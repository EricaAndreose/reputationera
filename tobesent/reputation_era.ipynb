{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reputation Era\n",
    "### How does the reputation of artists changes in time?\n",
    "\n",
    "This notebook contains the data mining and data analysis of the project Reputation Era, developed by Erica Andreose, Giorgia Crosilla and Daniele Spedicati in the context of the exam of Information Visualization. \n",
    "\n",
    "The project aims to explore the oscillations in reputation that different artists face during time through data. \n",
    "\n",
    "The concept of reputation is difficult to define and many definition could be given. First of all, we have considered differentiating the concepts of reputation and popularity where the former is more connected to the academic world and perception, while the latter is influenced by the consideration and fame among general people. \n",
    "\n",
    "To conduct a comprehensive analysis centered around the key concept of \"reputation,\" various variables have been considered to develop a quantitative method for its measurement. The starting point considered is the paper <a href=\"https://www.science.org/doi/full/10.1126/science.aau7224\">“Quantifying reputation and success in art”</a> which states “Recognition depends on variables like its attribution, the artist’s body of work, the display venue, and the work’s relationship to art history as a whole [...] are shaped by a network of experts, curators, collectors, and art historians whose judgments act as gatekeepers for museums, galleries, and auction houses” .\n",
    "Moreover it highlights that the quantitative analysis of the reputation of an artist is negatively influenced by the “fragmented and secretive nature” of transaction records leading to a difficulty to complete quantitative analysis is difficult and, as in this project, limited to an analysis of a limited span of time. \n",
    "\n",
    "By considering all of this, we have determined the concept of reputation as constituted of these following variables:\n",
    "- Auction houses sellings;\n",
    "- Bibliography;\n",
    "- Number of exhibitions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Datasets\n",
    "Even though these variables have been chosen for our analyses, they cannot be considered as complete sources of information for the following reasons:\n",
    "- Auction houses sellings is a dataset taken from <a href=\"https://raw.githubusercontent.com/jasonshi10/art_auction_valuation/master/data.txt\">repository</a> which has taken data webscraping the old website of <a href=\"https://web.archive.org/web/20141018210450/http://artsalesindex.artinfo.com/asi/search/artistLanding.ai\">Blouin Art Sales index</a>. During 2014 that website made available a lot of auction data for free, now data is available only under subscription as other websites like Artsy. It cannot be considered as a complete dataset because it does not represent all artists and it limits data at a time span between 1990s and 2014. Moreover, it takes into consideration a limited number of auction houses. Unfortunately this dataset does not assign a unique identifier per single artwork sold, so we do not know if similar titles are actually referring to a single artwork or not, the same to be said in the case of titled “Unknown” artworks. \n",
    "- Bibliography has been extrapolated from data.bnf and Google Books API merging the two outputs and removing duplicates. The choice of using these sources is dependent on the available and functioning sparql endpoints and it has been influenced by the non-free availability of Worldcat API. \n",
    "- Since no dataset has been created with the purpose of collecting information on exhibitions during the years, we chose to extract partial information from exhibition catalogues. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Case studies - De Kooning and Klimt\n",
    "For the development of our project we have considered two different case studies:\n",
    "- The painter <b>Willem de Kooning</b> has been considered as \"ground truth\" because the <a href=\"https://www.dekooning.org/\">website</a> of the Foundation dedicated to him reports all one-man exhibitions and monographs written on the artist. We consider this as an attempt to gather complete data on the artist and we used them to make a comparison between these data and the ones extrapolated from previously mentioned sources. \n",
    "- <b>Gustav Klimt</b> as a case study, where we used all the different sources to make our assumptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if you're using colab to install the following libraries\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install pandas\n",
    "# !pip install torch\n",
    "# !pip install spacy\n",
    "# !pip install beautifulsoup4\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all useful libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Auctions dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the auctions dataset as a Pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "auctions = pd.read_csv(\"auctions.csv\", sep=\";\", encoding=\"iso-8859-1\")\n",
    "\n",
    "def remove_last_zero(x):\n",
    "    if str(x).endswith('0'):\n",
    "        return str(x)[:-3]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# Apply the function to the 'price' column\n",
    "auctions['price'] = auctions['price'].apply(remove_last_zero)\n",
    "\n",
    "auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(auctions['artist']):\n",
    "    if isinstance(item, str) and 'After  ' in item:\n",
    "        auctions.at[i, 'artist'] = item.replace('After  ', '')\n",
    "auctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Brief overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we tally the frequency of each artist in the dataset to identify those with the most auction records. Then, we determine how often each artist has participated in auctions.\n",
    "\n",
    "**Research question**: Which artist presents a significant amount of data suitable for experimentation, based on the frequency of auction records and their participation in auctions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary with the frequency of each artist\n",
    "\n",
    "from collections import Counter\n",
    "liss = {}\n",
    "for column_name in auctions.columns:\n",
    "    if column_name == \"artist\":\n",
    "        for value in auctions[column_name]:\n",
    "            if value not in liss:\n",
    "                liss[value] = 1\n",
    "            else:\n",
    "                liss[value] += 1\n",
    "k = Counter(liss)\n",
    " \n",
    "# Finding 20 highest values\n",
    "high = k.most_common(20) \n",
    " \n",
    "print(\"Initial Dictionary:\")\n",
    "print(liss, \"\\n\")\n",
    "print ('Total artist', len(liss))\n",
    " \n",
    " \n",
    "print(\"Dictionary with 3 highest values:\")\n",
    "print(\"Keys: Values\")\n",
    " \n",
    "for i in high:\n",
    "    print(i[0],\" :\",i[1],\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our initial analysis, we observe a concentration of data on a small number of artists with a significant number of auction records, while many artists have only a few auction records. Consequently, we move forward by examining the distribution of artists within various ranges of auction activity on their works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the distribution of data in our dataset\n",
    "\n",
    "# Extract keys with value 1\n",
    "keys_with_value_1 = [key for key, value in k.items() if value == 1]\n",
    "\n",
    "# Count of keys with value 1\n",
    "count_keys_with_value_1 = len(keys_with_value_1)\n",
    "\n",
    "\n",
    "# Extract keys with value between 1 and 5\n",
    "keys_with_value_minor_5 = [key for key, value in k.items() if 1 < value <= 5]\n",
    "\n",
    "# Count of keys with value 5\n",
    "count_keys_with_value_minor_5 = len(keys_with_value_minor_5)\n",
    "\n",
    "\n",
    "# extract keys with value between 5 and 10\n",
    "keys_with_value_minor_10= [key for key, value in k.items() if 5 < value <= 10]\n",
    "\n",
    "# Count of keys with value between 5 and 10\n",
    "count_keys_with_value_minor_10 = len(keys_with_value_minor_10)\n",
    "\n",
    "\n",
    "# extract keys with value greater than 10\n",
    "keys_with_value_greater_10= [key for key, value in k.items() if value > 10]\n",
    "\n",
    "# Count of keys with value greater than 10\n",
    "count_keys_with_value_greater_10 = len(keys_with_value_greater_10)\n",
    "    \n",
    "\n",
    "# Organise data in a df\n",
    "\n",
    "data = {'labels':['Artist with one auction', 'Artists with maximum 5 auctions', 'Artist with maximum 10 auctions', 'Artists with more than 10 auctions'],\n",
    "        'values' : [count_keys_with_value_1, count_keys_with_value_minor_5, count_keys_with_value_minor_10, count_keys_with_value_greater_10]\n",
    "}\n",
    "\n",
    "auctions_count = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the sum of 'values' column\n",
    "total_value = auctions_count['values'].sum()\n",
    "\n",
    "# Add a new row with the label \"Artists in the dataset\" and the sum of all values\n",
    "new_row = {'labels': ['Artists in the dataset'], 'values': [total_value]}\n",
    "total_df = pd.DataFrame(new_row)\n",
    "# Concatenate the original DataFrame with the new total row DataFrame\n",
    "auctions_count = pd.concat([auctions_count, total_df], ignore_index=True)\n",
    "# Calculate percentages\n",
    "auctions_count['percentage'] = (auctions_count['values'] / total_value) * 100\n",
    "\n",
    "\n",
    "auctions_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent this data with a donut chart to illustrate the percentage of coverage for each range of auction activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create donut chart from data above\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# settings\n",
    "sizes = [count_keys_with_value_1, count_keys_with_value_minor_5, count_keys_with_value_minor_10, count_keys_with_value_greater_10]\n",
    "labels = ['Artist with one auction', 'Artists with maximum 5 auctions', 'Artist with maximum 10 auctions', 'Artists with more than 10 auctions']\n",
    "colors = ['#FFC3FF','#E9A2FF','#A664BC','#86469C']\n",
    "explode = [0, 0, 0, 0.1]\n",
    "\n",
    "# Create a pieplot\n",
    "plt.pie(sizes, labels=labels, colors=colors, explode=explode, autopct='%1.1f%%', startangle=0, pctdistance=0.5, textprops={'color': '#352f36'})\n",
    "\n",
    "# add a circle at the center to transform it into a donut chart\n",
    "my_circle = plt.Circle((0,0), 0.7, color='white')\n",
    "p = plt.gcf()\n",
    "p.gca().add_artist(my_circle)\n",
    "\n",
    "plt.title('Distribution of Artists by Number of Auctions performed on their works of art', color='#352f36')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initial plot indicates that only a fraction of our dataset is substantial enough for meaningful data-driven research. Consequently, we need to narrow our focus to one of the 17 artists. The following code extracts this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bar chart of frequency of auctions for artists with more than 10 auctions performed on their works.\n",
    "\n",
    "#create dictionary with only above 10\n",
    "greater_10_dict = {}\n",
    "for key, value in high:\n",
    "    if value > 10 :\n",
    "        greater_10_dict[key] = value\n",
    "\n",
    "data = {'artist': greater_10_dict.keys(), 'number of auctions': greater_10_dict.values()}\n",
    "\n",
    "\n",
    "greater_than_10_df = pd.DataFrame(data)\n",
    "\n",
    "greater_than_10_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize this data in a bar chart to observe the distribution differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot artists with more than 10 auctions\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set the style and color of the axes\n",
    "sns.set_style({'axes.edgecolor': 'gray', 'grid.color': '#dcdcdc'})\n",
    "\n",
    "sns.barplot(x='artist', y='number of auctions', data=greater_than_10_df, color='#86469C', zorder=2)  # Set zorder for the bars\n",
    "plt.xticks(rotation=45, ha='right', color='#352f36') \n",
    "plt.yticks(color='#352f36')\n",
    "plt.title('Auctions performed on artist', color='#352f36')\n",
    "plt.xlabel('Artist', color='#352f36')\n",
    "plt.ylabel('Number of Auctions', color='#352f36')\n",
    "sns.despine()\n",
    "plt.grid(True, axis='y', linestyle='-', zorder=1)  # Add horizontal grid lines with lower zorder\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the outliers (Pablo Picasso and Andy Warhol) to better visualize the distribution for other artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot without first two\n",
    "\n",
    "greater_10_df_filtered = greater_than_10_df.iloc[2:]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set the style and color of the axes\n",
    "sns.set_style({'axes.edgecolor': 'gray', 'grid.color': '#dcdcdc'})\n",
    "\n",
    "sns.barplot(x='artist', y='number of auctions', data=greater_10_df_filtered, color='#86469C', zorder=2)  # Set zorder for the bars\n",
    "plt.xticks(rotation=45, ha='right', color='#352f36') \n",
    "plt.yticks(color='#352f36')\n",
    "plt.title('Auctions performed on artist', color='#352f36')\n",
    "plt.xlabel('Artist', color='#352f36')\n",
    "plt.ylabel('Number of Auctions', color='#352f36')\n",
    "sns.despine()\n",
    "plt.grid(True, axis='y', linestyle='-', zorder=1)  # Add horizontal grid lines with lower zorder\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot indicates a group of artists whose works have been sold in auctions a similar number of times. Hence, we can conduct an analysis among them to comprehend the variations in data between each artist. Our choice of artists has been taken considering this bar plot, where we can see that the number of Klimt and De Kooning auctions records are quite similar in respect also to the timespan of auction records added onto the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "greater_10_df_filtered.to_csv('../docs//data/greater_10_filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Studying two artists: De Kooning and Klimt\n",
    "## Times a work has been sold\n",
    "\n",
    "In this section we analyse the mobility of works of De Kooning and Klimt. \n",
    "\n",
    "**Research question**: How many times have works by De Kooning and Klimt been sold, indicating their mobility in the market?\n",
    "\n",
    "### 1.2.1 De Kooning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count De Kooning frequency in the dataset\n",
    "\n",
    "liss_dk = []\n",
    "for column_name in auctions.columns:\n",
    "    if column_name == \"artist\":\n",
    "        for value in auctions[column_name]:\n",
    "            if value == \"Willem de Kooning\":\n",
    "                liss_dk.append(value)\n",
    "print(len(liss_dk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're exclusively retrieving results related to the chosen artists. Artworks lacking data about price and sold time have been removed from the dataset, reducing the number of considered examples to 307."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auctions per work of art De Kooning\n",
    "\n",
    "final_auctions_dk = auctions.loc[auctions[\"artist\"] == \"Willem de Kooning\", [\"artist\", \"name\", \"price\", \"soldtime\"]].copy()\n",
    "\n",
    "final_auctions_dk.dropna(subset=[\"price\", \"soldtime\"], inplace=True)\n",
    "\n",
    "\n",
    "# Extract the day from the \"soldtime\" column\n",
    "final_auctions_dk[\"soldtime\"] = final_auctions_dk[\"soldtime\"].str.split(\"-\").str[0]\n",
    "\n",
    "final_auctions_dk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "final_auctions_dk.to_csv('auctions_data_DK.csv', index=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "final_auctions_dk.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the frequency of each work title to determine the number of times each work has been sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are works that have been sold more than once\n",
    "\n",
    "name_counts = final_auctions_dk.groupby(['artist', 'name']).size().reset_index(name='count')\n",
    "\n",
    "name_counts_sorted_dk = name_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "name_counts_sorted_dk.reset_index(drop=True)\n",
    "\n",
    "name_counts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this initial overview, it's evident that there are likely multiple works titled \"Untitled\" (as the probability of one work being sold 90 times in eight years is very low). Unfortunately, our dataset lacks a unique identifier for each work, making it impossible to disambiguate them. \n",
    "\n",
    "We proceed to examine the frequency of different transaction counts to understand the rate of data mobility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of works sold in how many times\n",
    "\n",
    "# Count the occurrences of each count value\n",
    "count_freq = name_counts_sorted_dk['count'].value_counts().sort_index()\n",
    "\n",
    "# Create a DataFrame to store the count frequency data\n",
    "count_data_dk = pd.DataFrame({'times_sold':count_freq.index , 'count': count_freq.values})\n",
    "\n",
    "count_data_dk = count_data_dk.sort_values(by='times_sold', ascending=True)\n",
    "\n",
    "# Modify the 'times_sold' column to become a string\n",
    "count_data_dk['times_sold'] = 'sold ' + count_data_dk['times_sold'].astype(str) + ' times'\n",
    "\n",
    "count_data_dk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This code shows the plot of the above mentioned data. \n",
    "# #To make the notebook lighter we live it as not automatically runned\n",
    "# #To show it de comment the cell.\n",
    "\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Set the style and color of the axes\n",
    "# sns.set_style({'axes.edgecolor': 'gray', 'grid.color': '#dcdcdc'})\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(x='times_sold', y='count', data=count_data_dk, color='#E97D01', zorder = 4)\n",
    "\n",
    "# plt.title('Frequency of Times a work has been sold', color='#352f36')\n",
    "# plt.xlabel('Times Sold', color='#352f36')\n",
    "# plt.ylabel('Number of works', color='#352f36')\n",
    "# plt.xticks(rotation=45, color='#352f36')\n",
    "# plt.yticks(color='#352f36')\n",
    "\n",
    "# # Add exact value on top of each bar\n",
    "# for index, value in enumerate(count_data_dk['count']):\n",
    "#     plt.text(index, value + 0.5, str(value), ha='center', va='bottom', color='#352f36')\n",
    "\n",
    "# # Plot the grid lines behind the bars\n",
    "# plt.grid(True, axis='y', linestyle='-', zorder=0)  # Lower zorder for grid lines\n",
    "# sns.despine()\n",
    "# #\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Klimt\n",
    "\n",
    "We perform the same analysis on data about Klimt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Klimt frequency\n",
    "\n",
    "liss_k = []\n",
    "for column_name in auctions.columns:\n",
    "    if column_name == \"artist\":\n",
    "        for value in auctions[column_name]:\n",
    "            if value == \"Gustav Klimt\":\n",
    "                liss_k.append(value)\n",
    "print(len(liss_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klimt data\n",
    "\n",
    "final_auctions_k = auctions[[\"artist\", \"name\", \"price\", \"soldtime\"]].copy()\n",
    "final_auctions_k= final_auctions_k[final_auctions_k[\"artist\"] == \"Gustav Klimt\"].copy()\n",
    "\n",
    "final_auctions_k.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for idx, row in final_auctions_k.iterrows():\n",
    "    if pd.isna(row[\"price\"]) and pd.isna(row[\"soldtime\"]):\n",
    "        final_auctions_k.drop(idx, inplace=True)\n",
    "        \n",
    "dayy = []\n",
    "for i in final_auctions_k['soldtime']:\n",
    "    string_representation = str(i)\n",
    "    split_parts = string_representation.split('-')\n",
    "    day = split_parts[0]\n",
    "    dayy.append(day)\n",
    "final_auctions_k['soldtime'] = dayy\n",
    "        \n",
    "\n",
    "final_auctions_k.reset_index(drop=True, inplace=True)\n",
    "final_auctions_k.to_csv('auctions_data_k.csv', index=False)\n",
    "final_auctions_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are works that have been sold more than once\n",
    "\n",
    "name_counts = final_auctions_k.groupby(['artist', 'name']).size().reset_index(name='count')\n",
    "\n",
    "name_counts_sorted_k = name_counts.sort_values(by='count', ascending=False)\n",
    "\n",
    "name_counts_sorted_k.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of works sold in how many times\n",
    "\n",
    "# Count the occurrences of each count value\n",
    "count_freq = name_counts_sorted_k['count'].value_counts().sort_index()\n",
    "\n",
    "# Create a DataFrame to store the count frequency data\n",
    "count_data_k = pd.DataFrame({'times_sold':count_freq.index , 'count': count_freq.values})\n",
    "\n",
    "count_data_k = count_data_k.sort_values(by='times_sold', ascending=True)\n",
    "\n",
    "# Modify the 'times_sold' column to become a string\n",
    "count_data_k['times_sold'] = 'sold ' + count_data_k['times_sold'].astype(str) + ' times'\n",
    "\n",
    "count_data_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This code shows the plot of the above mentioned data. \n",
    "# #To make the notebook lighter we live it as not automatically runned\n",
    "# #To show it de comment the cell.\n",
    "\n",
    "# # Set the style and color of the axes\n",
    "# sns.set_style({'axes.edgecolor': 'gray', 'grid.color': '#dcdcdc'})\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(x='times_sold', y='count', data=count_data_k, color='#26408B', zorder=4)\n",
    "\n",
    "# plt.title('Frequency of Times a work has been sold', color='#352f36')\n",
    "# plt.xlabel('Times Sold', color='#352f36')\n",
    "# plt.ylabel('Number of works', color='#352f36')\n",
    "# plt.xticks(rotation=45, color='#352f36')\n",
    "# plt.yticks(color='#352f36')\n",
    "\n",
    "\n",
    "# # Add exact value on top of each bar\n",
    "# for index, value in enumerate(count_data_k['count']):\n",
    "#     plt.text(index, value + 0.5, str(value), ha='center', va='bottom', color='#352f36')\n",
    "\n",
    "# # Remove right and top border\n",
    "# sns.despine(right=True, top=True)\n",
    "\n",
    "# plt.grid(True, axis='y', linestyle='-', zorder=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Compare data\n",
    "\n",
    "To determine which artist's works are sold more times, we compare the number of art pieces that have been sold a certain number of times for each artist.\n",
    "\n",
    "**Research questions**: Whose works are sold more times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine data\n",
    "\n",
    "# Left merge df_dk and df_k on 'times_sold' column\n",
    "soldtime_merge_df = pd.merge(count_data_dk, count_data_k, on='times_sold', how='left')\n",
    "\n",
    "# Fill NaN values with 0\n",
    "soldtime_merge_df = soldtime_merge_df.fillna(0)\n",
    "\n",
    "# Rename the 'count' columns\n",
    "soldtime_merge_df = soldtime_merge_df.rename(columns={'count_x': 'de_kooning_count', 'count_y': 'klimt_count'})\n",
    "\n",
    "# Convert count columns to integer data type\n",
    "soldtime_merge_df['de_kooning_count'] = soldtime_merge_df['de_kooning_count'].astype(int)\n",
    "soldtime_merge_df['klimt_count'] = soldtime_merge_df['klimt_count'].astype(int)\n",
    "\n",
    "soldtime_merge_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bars\n",
    "barWidth = 0.3\n",
    "\n",
    "# Set the style and color of the axes\n",
    "sns.set_style({'axes.edgecolor': 'gray', 'grid.color': '#dcdcdc'})\n",
    " \n",
    "# set heights of bars\n",
    "bars1 = soldtime_merge_df['de_kooning_count']\n",
    "bars2 = soldtime_merge_df['klimt_count']\n",
    "\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    " \n",
    "# Make the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(r1, bars1, color='#E97D01', width=barWidth, edgecolor='white', label='De Kooning', zorder=4)\n",
    "plt.bar(r2, bars2, color='#26408B', width=barWidth, edgecolor='white', label='Klimt', zorder=4)\n",
    "\n",
    "for i, (dk_count, kl_count) in enumerate(zip(soldtime_merge_df['de_kooning_count'], soldtime_merge_df['klimt_count'])):\n",
    "    if dk_count > 0:\n",
    "        plt.text(i, dk_count + 0.5, str(dk_count), ha='center', va='bottom', color='#352f36')\n",
    "    if kl_count > 0:\n",
    "        plt.text(i + barWidth, kl_count + 0.5, str(kl_count), ha='center', va='bottom', color= '#352f36')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.title('Frequency of Times a work has been sold', color='#352f36')\n",
    "plt.xlabel('Times Sold', color='#352f36')\n",
    "plt.ylabel('Number of works', color='#352f36')\n",
    "plt.yticks(color='#352f36')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], soldtime_merge_df['times_sold'], rotation=45, color='#352f36')\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='-', zorder=0)\n",
    "\n",
    "# Remove right and top border\n",
    "sns.despine(right=True, top=True)\n",
    "\n",
    "plt.tight_layout()\n",
    " \n",
    "# Create legend & Show graphic\n",
    "legend = plt.legend()\n",
    "\n",
    "# Set the color of the legend labels\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('#352f36')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: This analysis highlights that although Klimt has more works sold, De Kooning's works tend to change ownership more frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "soldtime_merge_df.to_csv('../docs/data/soldtime_merge_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Sellings per year\n",
    "\n",
    "In this section, we evaluate the distribution of auctions selling works of our two artists per year.\n",
    "\n",
    "**Research question**: How many auctions for each artist have been performed per year?\n",
    "### 1.3.1 De Kooning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values in the 'soldtime' column\n",
    "soldtime_counts_dk = final_auctions_dk['soldtime'].value_counts()\n",
    "\n",
    "# Convert the Series to a DataFrame if needed\n",
    "soldtime_counts_df = soldtime_counts_dk.reset_index()\n",
    "soldtime_counts_df.columns = ['soldtime', 'count']\n",
    "\n",
    "# Sort the DataFrame by the 'soldtime' column\n",
    "soldtime_counts_df_sorted_dk = soldtime_counts_df.sort_values(by='soldtime')\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "soldtime_counts_df_sorted_dk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This code shows the plot of the above mentioned data.\n",
    "# #To make the notebook lighter we live it as not automatically runned\n",
    "# #To show it de comment the cell.\n",
    "\n",
    "\n",
    "# # Plot the timeline\n",
    "\n",
    "# # Set the style and color of the axes\n",
    "# sns.set_style({'axes.edgecolor': 'gray', 'grid.color': '#dcdcdc'})\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Plot horizontal grid lines behind the line plot\n",
    "# plt.grid(True, axis='y', linestyle='-', zorder=0)\n",
    "\n",
    "# sns.lineplot(x=\"soldtime\", y=\"count\", data=soldtime_counts_df_sorted_dk, color='#E97D01') \n",
    "\n",
    "# plt.title('Sales per year', color='#352f36')\n",
    "# plt.xlabel('Year', color='#352f36')\n",
    "# plt.ylabel('Number of sales', color='#352f36')\n",
    "\n",
    "# # Remove right and top border\n",
    "# sns.despine(right=True, top=True)\n",
    "\n",
    "# plt.yticks(color='#352f36')\n",
    "# plt.xticks(color='#352f36')\n",
    "# #\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the values in the 'soldtime' column\n",
    "soldtime_counts_k = final_auctions_k['soldtime'].value_counts()\n",
    "\n",
    "# Convert the Series to a DataFrame if needed\n",
    "soldtime_counts_df = soldtime_counts_k.reset_index()\n",
    "soldtime_counts_df.columns = ['soldtime', 'count']\n",
    "\n",
    "# Sort the DataFrame by the 'soldtime' column\n",
    "soldtime_counts_df_sorted_k = soldtime_counts_df.sort_values(by='soldtime')\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "soldtime_counts_df_sorted_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This code shows the plot of the above mentioned data.\n",
    "# #To make the notebook lighter we live it as not automatically runned\n",
    "# #To show it de comment the cell.\n",
    "\n",
    "# # Plot the timeline\n",
    "\n",
    "# # Set the style and color of the axes\n",
    "# sns.set_style({'axes.edgecolor': 'gray', 'grid.color': '#dcdcdc'})\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Plot horizontal grid lines behind the line plot\n",
    "# plt.grid(True, axis='y', linestyle='-', zorder=0)\n",
    "\n",
    "# sns.lineplot(x=\"soldtime\", y=\"count\", data=soldtime_counts_df_sorted_dk, color='#26408B') \n",
    "\n",
    "# plt.title('Sales per year', color='#352f36')\n",
    "# plt.xlabel('Year', color='#352f36')\n",
    "# plt.ylabel('Number of sales', color='#352f36')\n",
    "\n",
    "# # Remove right and top border\n",
    "# sns.despine(right=True, top=True)\n",
    "\n",
    "# plt.yticks(color='#352f36')\n",
    "# plt.xticks(color='#352f36')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Compare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and displaying the change in the number of sales per year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'soldtime' columns to int64 if they are not already\n",
    "soldtime_counts_df_sorted_dk['soldtime'] = soldtime_counts_df_sorted_dk['soldtime'].astype('int64')\n",
    "soldtime_counts_df_sorted_k['soldtime'] = soldtime_counts_df_sorted_k['soldtime'].astype('int64')\n",
    "\n",
    "# Right merge the DataFrames on the 'soldtime' column\n",
    "selling_per_year = pd.merge(soldtime_counts_df_sorted_dk, soldtime_counts_df_sorted_k, on='soldtime', how='right')\n",
    "\n",
    "# Rename the count columns\n",
    "selling_per_year.rename(columns={'count_x': 'de kooning count', 'count_y': 'klimt count'}, inplace=True)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "selling_per_year.fillna(0, inplace=True)\n",
    "\n",
    "# Convert the count columns to int64\n",
    "selling_per_year['de kooning count'] = selling_per_year['de kooning count'].astype('int64')\n",
    "selling_per_year['klimt count'] = selling_per_year['klimt count'].astype('int64')\n",
    "\n",
    "# Sort by 'soldtime'\n",
    "selling_per_year.sort_values(by='soldtime', inplace=True)\n",
    "\n",
    "# Display the merged and sorted DataFrame\n",
    "selling_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a new figure and axes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Filter out rows where \"de kooning count\" is not equal to 0\n",
    "de_kooning_filtered = selling_per_year[selling_per_year['de kooning count'] != 0]\n",
    "\n",
    "# Filter out rows where \"klimt count\" is not equal to 0\n",
    "klimt_filtered = selling_per_year[selling_per_year['klimt count'] != 0]\n",
    "\n",
    "# Plot \"de kooning count\"\n",
    "if not de_kooning_filtered.empty:\n",
    "    sns.lineplot(x=\"soldtime\", y=\"de kooning count\", data=de_kooning_filtered, color='#E97D01', zorder=4, label='De Kooning')\n",
    "\n",
    "# Plot \"klimt count\" if \"klimt count\" is not empty\n",
    "if not klimt_filtered.empty:\n",
    "    sns.lineplot(x=\"soldtime\", y=\"klimt count\", data=klimt_filtered, color='#26408B', zorder=4, label='Klimt')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Sales per year', color='#352f36')\n",
    "plt.xlabel('Year', color='#352f36')\n",
    "plt.ylabel('Number of sales', color='#352f36')\n",
    "plt.xticks(color='#352f36')\n",
    "plt.yticks(color='#352f36')\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "\n",
    "# Set the color of the legend labels\n",
    "legend = plt.legend()\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('#352f36')\n",
    "\n",
    "# Remove right and top border\n",
    "sns.despine(right=True, top=True)\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='-', zorder=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that in the common time span (2008-2014), Klimt has experienced a decrease in sales, while the opposite trend can be observed for De Kooning. However, it's worth noting that in the last year considered (2014), De Kooning's sales were halved compared to the previous year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selling_per_year.to_csv('../docs/data/selling_per_year.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Price of sellings\n",
    "\n",
    "In this section we study the variation of price in time.\n",
    "\n",
    "**Research question**: How do the prices change in time?\n",
    "### 1.4.1 De Kooning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sellings at time and price De Kooning\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Convert 'soldtime' and 'price' columns to numeric data types if they are not already\n",
    "final_auctions_dk['soldtime'] = pd.to_numeric(final_auctions_dk['soldtime'], errors='coerce')\n",
    "final_auctions_dk['price'] = pd.to_numeric(final_auctions_dk['price'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values if any\n",
    "final_auctions_dk = final_auctions_dk.dropna(subset=['soldtime', 'price'])\n",
    "\n",
    "# Plot the scatter plot with regression line\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.regplot(x='soldtime', y='price', data=final_auctions_dk, color='#E97D01', scatter_kws={'s': 5}, line_kws={'linewidth': 1})\n",
    "\n",
    "# Format y-axis ticks\n",
    "formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Year', color='#352f36')\n",
    "plt.ylabel('Price', color='#352f36')\n",
    "plt.title('Price of Sellings per year', color='#352f36')\n",
    "plt.xticks(color='#352f36')\n",
    "plt.yticks(color='#352f36')\n",
    "\n",
    "# Remove left and top border\n",
    "sns.despine(right=True, top=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presented like this, it's challenging to grasp the precise values for each layer. Therefore, we round the data to the nearest 10 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the 'price' values to the nearest million\n",
    "rounded_prices = (final_auctions_dk['price'] // 10000000) * 10000000\n",
    "\n",
    "# Create a new DataFrame with 'soldtime', 'rounded_prices', and 'count'\n",
    "rounded_prices_df_dk = final_auctions_dk.groupby(['soldtime', rounded_prices]).size().reset_index(name='count')\n",
    "\n",
    "# Rename columns\n",
    "rounded_prices_df_dk.rename(columns={rounded_prices.name: 'rounded_prices'}, inplace=True)\n",
    "\n",
    "# Sort the DataFrame by 'soldtime'\n",
    "rounded_prices_df_dk.sort_values(by='soldtime', inplace=True)\n",
    "\n",
    "# Display the new DataFrame\n",
    "rounded_prices_df_dk.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This code shows the plot of the above mentioned data.\n",
    "# #To make the notebook lighter we live it as not automatically runned\n",
    "# #To show it de comment the cell.\n",
    "\n",
    "# # Plot grouped count \n",
    "\n",
    "# # Define the two colors\n",
    "# color1 = '#FCAC23'  # Yellow\n",
    "# color2 = '#B53302'  # Red\n",
    "\n",
    "\n",
    "# # Create a custom colormap gradient\n",
    "# cmap = LinearSegmentedColormap.from_list('custom_gradient', [color1, color2])\n",
    "\n",
    "\n",
    "# # Create the bubble chart with color gradient based on 'count'\n",
    "# plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "# sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=rounded_prices_df_dk, legend=True, palette=cmap, sizes=(50,200))\n",
    "\n",
    "\n",
    "# # Format y-axis ticks\n",
    "# formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "# plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# # Set the labels and title\n",
    "# plt.xlabel('Year', color='#352f36')\n",
    "# plt.ylabel('Price', color='#352f36')\n",
    "# plt.title('Price of Sellings per year', color='#352f36')\n",
    "# plt.xticks(color='#352f36')\n",
    "# plt.yticks(color='#352f36')\n",
    "\n",
    "# # Set the color of the legend labels\n",
    "# legend = plt.legend(title = 'Number of sales',  loc='upper left')\n",
    "# for text in legend.get_texts():\n",
    "#     text.set_color('#352f36')\n",
    "\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sellings at time and price Klimt\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Convert 'soldtime' and 'price' columns to numeric data types if they are not already\n",
    "final_auctions_k['soldtime'] = pd.to_numeric(final_auctions_k['soldtime'], errors='coerce')\n",
    "final_auctions_k['price'] = pd.to_numeric(final_auctions_k['price'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values if any\n",
    "final_auctions_k = final_auctions_k.dropna(subset=['soldtime', 'price'])\n",
    "\n",
    "# Plot the scatter plot with regression line\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.regplot(x='soldtime', y='price', data=final_auctions_k, color='#26408B', scatter_kws={'s': 5}, line_kws={'linewidth': 1})\n",
    "\n",
    "# Format y-axis ticks\n",
    "formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Year', color='#352f36')\n",
    "plt.ylabel('Price', color='#352f36')\n",
    "plt.title('Price of Selling per year', color='#352f36')\n",
    "plt.xticks(color='#352f36')\n",
    "plt.yticks(color='#352f36')\n",
    "\n",
    "# Remove left and top border\n",
    "sns.despine(right=True, top=True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as for de Kooning, we now show de distribution of values to make more explicit the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round the 'price' values to the nearest million\n",
    "rounded_prices = (final_auctions_k['price'] // 10000000) * 10000000\n",
    "\n",
    "# Create a new DataFrame with 'soldtime', 'rounded_prices', and 'count'\n",
    "rounded_prices_df_k = final_auctions_k.groupby(['soldtime', rounded_prices]).size().reset_index(name='count')\n",
    "\n",
    "# Rename columns\n",
    "rounded_prices_df_k.rename(columns={rounded_prices.name: 'rounded_prices'}, inplace=True)\n",
    "\n",
    "# Sort the DataFrame by 'soldtime'\n",
    "rounded_prices_df_k.sort_values(by='soldtime', inplace=True)\n",
    "\n",
    "# Display the new DataFrame\n",
    "rounded_prices_df_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the two colors\n",
    "# color3 = '#81B1D5'  # Light blue\n",
    "# color4 = '#0F084B'  # Dark blue\n",
    "\n",
    "\n",
    "# # Create a custom colormap gradient\n",
    "# cmap = LinearSegmentedColormap.from_list('custom_gradient', [color3, color4])\n",
    "\n",
    "\n",
    "# # Create the bubble chart with color gradient based on 'count'\n",
    "# plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "# sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=rounded_prices_df_k, legend=True, palette=cmap, sizes=(50,200))\n",
    "\n",
    "\n",
    "# # Format y-axis ticks\n",
    "# formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "# plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# # Set the labels and title\n",
    "# plt.xlabel('Year', color='#352f36')\n",
    "# plt.ylabel('Price', color='#352f36')\n",
    "# plt.title('Price of Sellings per year', color='#352f36')\n",
    "# plt.xticks(color='#352f36')\n",
    "# plt.yticks(color='#352f36')\n",
    "\n",
    "# # Set the color of the legend labels\n",
    "# legend = plt.legend(title = 'Number of sales')\n",
    "# for text in legend.get_texts():\n",
    "#     text.set_color('#352f36')\n",
    "\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Compare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the data from the two artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Define the two colors\n",
    "color1 = '#FCAC23'  # Yellow\n",
    "color2 = '#B53302'  # Red\n",
    "\n",
    "# Create a custom colormap gradient\n",
    "cmap_orange = LinearSegmentedColormap.from_list('custom_gradient', [color1, color2])\n",
    "\n",
    "# Define the two colors for the custom gradient\n",
    "color3 = '#81B1D5'  # Light blue\n",
    "color4 = '#0F084B'  # Dark blue\n",
    "\n",
    "# Create a custom colormap gradient\n",
    "cmap_blue = LinearSegmentedColormap.from_list('custom_gradient', [color3, color4])\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot for rounded_prices_df_dk\n",
    "sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=rounded_prices_df_dk, ax=axs[0], legend=True, palette=cmap_orange, sizes=(50,200))\n",
    "axs[0].set_title('Price of Sellings per year - De Kooning', color='#352f36')\n",
    "axs[0].set_xlabel('Year', color='#352f36')\n",
    "axs[0].set_ylabel('Number of Sales', color='#352f36')\n",
    "\n",
    "# Customize ticks color\n",
    "axs[0].tick_params(axis='x', colors='#352f36')\n",
    "axs[0].tick_params(axis='y', colors='#352f36')\n",
    "\n",
    "# Customize legend text color\n",
    "legend = axs[0].legend(title='Number of sales')\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('#352f36')\n",
    "\n",
    "# Set legend title color\n",
    "legend.get_title().set_color('#352f36')\n",
    "\n",
    "# Format y-axis ticks\n",
    "formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "axs[0].yaxis.set_major_formatter(formatter)\n",
    "\n",
    "\n",
    "# Plot for rounded_prices_df_k\n",
    "sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=rounded_prices_df_k, ax=axs[1], legend=True, palette=cmap_blue, sizes=(50,200))\n",
    "axs[1].set_title('Price of Sellings per year - Klimt', color='#352f36')\n",
    "axs[1].set_xlabel('Year', color='#352f36')\n",
    "axs[1].set_ylabel('Number of Sales', color='#352f36')\n",
    "\n",
    "# Customize ticks color\n",
    "axs[1].tick_params(axis='x', colors='#352f36')\n",
    "axs[1].tick_params(axis='y', colors='#352f36')\n",
    "\n",
    "# Customize legend text color\n",
    "legend = axs[1].legend(title='Number of sales')\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('#352f36')\n",
    "\n",
    "# Set legend title color\n",
    "legend.get_title().set_color('#352f36')\n",
    "\n",
    "# Format y-axis ticks\n",
    "formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "axs[1].yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Match x-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_xlim(axs[1].get_xlim())\n",
    "\n",
    "# Match y-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_ylim(axs[1].get_ylim())\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this initial comparison, it appears that Klimt had significant market interest between 2005 and 2007, while the peak year for De Kooning was 2013, marked by numerous low-price auctions alongside a few high-priced ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis shows us that the price for both Klimt and De Kooning works are pretty similar, and that interest in De Kooning is way higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Studying the mean\n",
    "Here we study the distribution of the mean\n",
    "\n",
    "### 1.5.1 De Kooning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean price per year de Kooning\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Calculate the mean price for each value of 'soldtime'\n",
    "mean_price_per_year_dk = final_auctions_dk.groupby('soldtime')['price'].mean()\n",
    "\n",
    "\n",
    "# Assuming 'mean_price_per_year_dk' is the Series containing mean price per year\n",
    "mean_price_per_year_dk_df = mean_price_per_year_dk.reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "mean_price_per_year_dk_df.columns = ['soldtime', 'mean']\n",
    "# Print the mean price for each year\n",
    "mean_price_per_year_dk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##This code shows the plot of the above mentioned data.\n",
    "# ##To make the notebook lighter we live it as not automatically runned\n",
    "# ##To show it de comment the cell.\n",
    "\n",
    "# # Plot the variation of mean price per year\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# mean_price_per_year_dk.plot(kind='line', marker='o', color='#E97D01')\n",
    "\n",
    "# # Format y-axis ticks\n",
    "# formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "# plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "# plt.title('Mean of Price per Year', color='#352f36')  # Change title color\n",
    "# plt.xlabel('Year', color='#352f36')  # Change xlabel color\n",
    "# plt.ylabel('Mean of Price', color='#352f36')  # Change ylabel color\n",
    "# plt.xticks(color='#352f36')  # Change xticks color\n",
    "# plt.yticks(color='#352f36')  # Change yticks color\n",
    "# plt.grid(axis='y')  # Show only horizontal grid\n",
    "# sns.despine(right=True, top=True)  # Remove right and top border\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median price per year Klimt\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "\n",
    "# Calculate the mean price for each value of 'soldtime'\n",
    "mean_price_per_year_k = final_auctions_k.groupby('soldtime')['price'].median()\n",
    "\n",
    "\n",
    "# Assuming 'mean_price_per_year_k' is the Series containing mean price per year\n",
    "mean_price_per_year_k_df = mean_price_per_year_k.reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "mean_price_per_year_k_df.columns = ['soldtime', 'mean']\n",
    "# Print the mean price for each year\n",
    "mean_price_per_year_k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##This code shows the plot of the above mentioned data.\n",
    "# ##To make the notebook lighter we live it as not automatically runned\n",
    "# ##To show it de comment the cell.\n",
    "\n",
    "# # Plot the variation of mean price per year\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# mean_price_per_year_k.plot(kind='line', marker='o', color='#26408B')\n",
    "\n",
    "# # Format y-axis ticks\n",
    "# formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x) if x < 1000000 else '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "# plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "\n",
    "# plt.title('Mean of Price per Year', color='#352f36')  # Change title color\n",
    "# plt.xlabel('Year', color='#352f36')  # Change xlabel color\n",
    "# plt.ylabel('Mean of Price', color='#352f36')  # Change ylabel color\n",
    "# plt.xticks(color='#352f36')  # Change xticks color\n",
    "# plt.yticks(color='#352f36')  # Change yticks color\n",
    "# plt.grid(axis='y')  # Show only horizontal grid\n",
    "# sns.despine(right=True, top=True)  # Remove right and top border\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 Compare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_mean_price_per_year = mean_price_per_year_k_df.merge(mean_price_per_year_dk_df, on='soldtime', suffixes=('_k', '_dk'))\n",
    "combined_mean_price_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the mean price variation per year for Klimt\n",
    "plt.plot(combined_mean_price_per_year.index, combined_mean_price_per_year['mean_k'], marker='o', color='#26408B', label='Klimt')\n",
    "\n",
    "# Plot the mean price variation per year for De Kooning\n",
    "plt.plot(combined_mean_price_per_year.index, combined_mean_price_per_year['mean_dk'], marker='o', color='#E97D01', label='De Kooning')\n",
    "\n",
    "# Format y-axis ticks\n",
    "formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x) if x < 1000000 else '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.title('Mean Price Variation per Year', color='#352f36')  # Change title color\n",
    "plt.xlabel('Year', color='#352f36')  # Change xlabel color\n",
    "plt.ylabel('Mean Price', color='#352f36')  # Change ylabel color\n",
    "plt.xticks(color='#352f36')  # Change xticks color\n",
    "plt.yticks(color='#352f36')  # Change yticks color\n",
    "plt.grid(axis='y')  # Show only horizontal grid\n",
    "sns.despine(right=True, top=True)  # Remove right and top border\n",
    "\n",
    "# Set legend labels and colors\n",
    "legend = plt.legend(loc='upper left', title='Artists')\n",
    "plt.setp(legend.get_title(), color='#352f36')  # Set legend title color\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('#352f36')  # Set legend label color\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Define the two colors for the custom gradient\n",
    "color1 = '#FCAC23'  # Yellow\n",
    "color2 = '#B53302'  # Red\n",
    "color3 = '#81B1D5'  # Light blue\n",
    "color4 = '#0F084B'  # Dark blue\n",
    "\n",
    "# Create custom colormaps\n",
    "cmap_orange = LinearSegmentedColormap.from_list('custom_gradient_orange', [color1, color2])\n",
    "cmap_blue = LinearSegmentedColormap.from_list('custom_gradient_blue', [color3, color4])\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot for rounded_prices_df_dk\n",
    "sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=rounded_prices_df_dk, ax=axs[0], legend=True, palette=cmap_orange, sizes=(50,200), alpha=0.8)\n",
    "axs[0].set_title('Price of Sellings per year - Klimt', color='#352f36')\n",
    "axs[0].set_xlabel('Year', color='#352f36')\n",
    "axs[0].set_ylabel('Number of Sales', color='#352f36')\n",
    "\n",
    "# Customize ticks color\n",
    "axs[0].tick_params(axis='x', colors='#352f36')\n",
    "axs[0].tick_params(axis='y', colors='#352f36')\n",
    "\n",
    "# Customize legend text color\n",
    "legend = axs[0].legend(title='Number of sales')\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('#352f36')\n",
    "\n",
    "# Set legend title color\n",
    "legend.get_title().set_color('#352f36')\n",
    "\n",
    "# Plot the line plot for mean price per year for final_auctions_dk\n",
    "mean_price_per_year_dk = final_auctions_dk.groupby('soldtime')['price'].mean()\n",
    "axs[0].plot(mean_price_per_year_dk.index, mean_price_per_year_dk.values, color='#E97D01', linestyle='-', linewidth=1)\n",
    "\n",
    "# Plot for rounded_prices_df_k\n",
    "sns.scatterplot(x='soldtime', y='rounded_prices', size='count', hue='count', data=rounded_prices_df_k, ax=axs[1], legend=True, palette=cmap_blue, sizes=(50,200), alpha=0.8)\n",
    "axs[1].set_title('Price of Sellings per year - Klimt', color='#352f36')\n",
    "axs[1].set_xlabel('Year', color='#352f36')\n",
    "axs[1].set_ylabel('Number of Sales', color='#352f36')\n",
    "\n",
    "# Customize ticks color\n",
    "axs[1].tick_params(axis='x', colors='#352f36')\n",
    "axs[1].tick_params(axis='y', colors='#352f36')\n",
    "\n",
    "# Customize legend text color\n",
    "legend = axs[1].legend(title='Number of sales')\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('#352f36')\n",
    "\n",
    "# Set legend title color\n",
    "legend.get_title().set_color('#352f36')\n",
    "\n",
    "# Plot the line plot for mean price per year for final_auctions_k\n",
    "mean_price_per_year_k = final_auctions_k.groupby('soldtime')['price'].mean()\n",
    "axs[1].plot(mean_price_per_year_k.index, mean_price_per_year_k.values, color='#26408B', linestyle='-', linewidth=1)\n",
    "\n",
    "# Match x-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_xlim(axs[1].get_xlim())\n",
    "\n",
    "# Match y-axis limits of the second subplot to the first subplot\n",
    "axs[0].set_ylim(axs[1].get_ylim())\n",
    "\n",
    "# Format y-axis ticks\n",
    "\n",
    "formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "axs[0].yaxis.set_major_formatter(formatter)\n",
    "\n",
    "formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'mln')\n",
    "axs[1].yaxis.set_major_formatter(formatter)\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_prices_df_dk.to_csv('../docs/data/rounded_count_dk.csv', index=False)\n",
    "mean_price_per_year_dk.to_csv('../docs/data/mean_price_per_year_dk.csv', index=False)\n",
    "rounded_prices_df_k.to_csv('../docs/data/rounded_count_k.csv', index=False)\n",
    "mean_price_per_year_k.to_csv('../docs/data/mean_price_per_year_k.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Cleaning\n",
    "### 2.1.1 data bnf\n",
    "#### 2.1.1.1 De Kooning\n",
    "\n",
    "\n",
    "Since accessing the sparql endpoint of data.bnf using python returns an empty html page, we performed the following query using the web endpoint  <a href=\"https://data.bnf.fr/sparql/\">data.bnf</a>:\n",
    "```\n",
    "PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX bnf-onto: <http://data.bnf.fr/ontology/bnf-onto/>\n",
    "SELECT * \n",
    "WHERE {\n",
    "  ?work dct:title ?title ;\n",
    "        dct:publisher ?publisher;\n",
    "        dct:date ?date;\n",
    "        rdfs:seeAlso ?uri ;\n",
    "        bnf-onto:isbn ?isbn;\n",
    "        \n",
    "  FILTER (bif:contains(?title, \"De_Kooning\"))}\n",
    "\n",
    "```\n",
    "\n",
    "The first query works at FRBR Work level, not allowing to extract directly the author of the work, because it's not an information contained at this level. After that a CSV containing dataset was downloaded and analyzed. \n",
    "\n",
    "The following query has been performed also:\n",
    "\n",
    "\n",
    "```\n",
    "PREFIX rdarelationships: <http://rdvocab.info/RDARelationshipsWEMI/>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX bnf-onto: <http://data.bnf.fr/ontology/bnf-onto/>\n",
    "SELECT distinct ?work ?title ?creatorname ?date ?isbn\n",
    "WHERE {\n",
    "  ?work dct:title ?title;\n",
    "        dct:creator ?creator.\n",
    "\t\t?creator foaf:name ?creatorname.\n",
    "  ?work dct:date ?date.\n",
    "  ?work rdarelationships:expressionOfWork ?expression.\n",
    "?manifestation rdarelationships:expressionManifested ?expression.\n",
    "?manifestation bnf-onto:isbn ?isbn.  \n",
    "  FILTER (bif:contains(?title, \"De_Kooning\"))}\n",
    "```\n",
    "\n",
    "This query works at the FRBR Manifestation level, it allows to gather all data needed for our needs but unfortunately the number of manifestations which have associated an author are a limited number. For this reason, we decided to stick with the query with more results, even though this could mean sacrificing some important metadata that could be used for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bnf_dk = pd.read_csv(\"databnf_DK.csv\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "bnf_dk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting De Kooning occurrences in the title of the dataframe\n",
    "liss = []\n",
    "for column_name in bnf_dk.columns:\n",
    "    if column_name == \"title\":\n",
    "        for value in bnf_dk[column_name]:\n",
    "            if \"de Kooning\" in value or \"De Kooning\" in value:\n",
    "                liss.append(value)\n",
    "print(len(liss))\n",
    "\n",
    "row_count = bnf_dk.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are altering the structure of the identifier (ISBN) here, as it will later need to be standardized for comparison with results obtained from the Google API. The Google API provides various identifiers, not just ISBNs, so this standardization ensures that potential duplicates in the dataset which will combine data from data.bnf and Google can be detected only when a direct ISBN comparison is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in bnf_dk.columns:\n",
    "    if column_name == \"isbn\":\n",
    "        for i, value in enumerate(bnf_dk[column_name]):\n",
    "            if \"-\" in value:\n",
    "                # Replacing hyphens with empty string\n",
    "                bnf_dk.at[i, column_name] = value.replace(\"-\", \"\")\n",
    "bnf_dk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2.1 Klimt\n",
    "\n",
    "In this case the query performed is this:\n",
    "```PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "PREFIX dct: <http://purl.org/dc/terms/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX bnf-onto: <http://data.bnf.fr/ontology/bnf-onto/>\n",
    "SELECT * \n",
    "WHERE {\n",
    "  ?work dct:title ?title ;\n",
    "        dct:publisher ?publisher;\n",
    "        dct:date ?date;\n",
    "        rdfs:seeAlso ?uri ;\n",
    "        bnf-onto:isbn ?isbn\n",
    "  FILTER (bif:contains(?title, \"Klimt\"))}\n",
    "  ```\n",
    "\n",
    " done on the web endpoint and then the CSV was downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnf_k = pd.read_csv(\"databnf_KLI.csv\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "bnf_k.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in bnf_k.columns:\n",
    "    if column_name == \"isbn\":\n",
    "        for i, value in enumerate(bnf_k[column_name]):\n",
    "            if \"-\" in value:\n",
    "                # Replacing hyphens with empty string\n",
    "                bnf_k.at[i, column_name] = value.replace(\"-\", \"\")\n",
    "bnf_k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Query on Google Books Api\n",
    "We used an HTTP request to query the Google Books API. The results produced are not completely coherent with the request, so after fetching the information, a further filtering was needed\n",
    "#### 2.1.2.1 De Kooning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_books(query, max_results=40):\n",
    "    base_url = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "    start_index = 0\n",
    "    all_results = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"startIndex\": start_index,\n",
    "            \"maxResults\": max_results\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            items = data.get(\"items\", [])\n",
    "            if not items:\n",
    "                break\n",
    "            all_results.extend(items)\n",
    "            start_index += max_results\n",
    "        else:\n",
    "            print(\"Failed to retrieve data. Status code:\", response.status_code)\n",
    "            break\n",
    "\n",
    "    return all_results\n",
    "\n",
    "books_dk = fetch_books(\"De Kooning\")\n",
    "\n",
    "# Saving JSON data to a file\n",
    "with open(\"dkbooks.json\", \"w\") as json_file:\n",
    "    json.dump(books_dk, json_file, indent=4)\n",
    "\n",
    "print(\"JSON data saved to dkbooks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON data from file\n",
    "with open(\"dkbooks.json\", \"r\") as json_file:\n",
    "    books_data_dk = json.load(json_file)\n",
    "\n",
    "# Extract relevant fields from each book item\n",
    "books_list_dk = []\n",
    "for book in books_data_dk:\n",
    "    book_info = {\n",
    "        \"Title\": book[\"volumeInfo\"].get(\"title\", \"N/A\"),\n",
    "        \"Subtitle\": book[\"volumeInfo\"].get(\"subtitle\", \"N/A\"),\n",
    "        \"Authors\": \", \".join(book[\"volumeInfo\"].get(\"authors\", [\"N/A\"])),\n",
    "        \"Publisher\": book[\"volumeInfo\"].get(\"publisher\", \"N/A\"),\n",
    "        \"PublishedDate\": book[\"volumeInfo\"].get(\"publishedDate\", \"N/A\"),\n",
    "        \"isbn\": book[\"volumeInfo\"].get(\"industryIdentifiers\", [{}])[0].get(\"identifier\", \"N/A\"),  # Retrieving ISBN\n",
    "    }\n",
    "    books_list_dk.append(book_info)\n",
    "\n",
    "# Create DataFrame\n",
    "books_df_dk = pd.DataFrame(books_list_dk)\n",
    "books_df_dk.replace('N/A', np.nan, inplace= True)\n",
    "\n",
    "# Display DataFrame\n",
    "books_df_dk.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking how many times De Kooning appears in the title\n",
    "liss = []\n",
    "for column_name in books_df_dk.columns:\n",
    "    if column_name == \"Title\":\n",
    "        for value in books_df_dk[column_name]:\n",
    "            if \"de Kooning\" in value or \"De Kooning\" in value:\n",
    "                liss.append(value)\n",
    "print(len(liss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering has been done considering the title and in particular the surname of the author in order to avoid results related to his wife that were showing up consistenly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "books_dk = books_df_dk[books_df_dk[\"Title\"].str.contains(\"de Kooning\", case=False) & ~books_df_dk[\"Title\"].str.contains(\"Elaine de Kooning\", case=False)].copy()\n",
    "\n",
    "books_dk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "books_dk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'ISBN' column\n",
    "df_combined_dk= pd.merge(bnf_dk, books_dk, on='isbn', how='inner')\n",
    "\n",
    "# Display the new DataFrame with rows where ISBN is found in both DataFrames\n",
    "df_combined_dk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part creates a complete dataframe of records gathering information from both data.bnf and Google books API while dropping duplicates based on ISBN and merging together title and subtitle. This last step was done to allow a future comparison with exhibition catalogues. Moreover, in this case the dataset contains both data regarding books and exhibition classes, two types of publications that are furtherly distinguished and analyzed later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'Title' column in df2 to 'title'\n",
    "books_dk.rename(columns={'Title': 'title'}, inplace=True)\n",
    "books_dk.rename(columns={'PublishedDate': 'date'}, inplace=True)\n",
    "books_dk.rename(columns={'Publisher': 'publisher'}, inplace=True)\n",
    "# Concatenate the DataFrames vertically\n",
    "combined_df = pd.concat([bnf_dk, books_dk], ignore_index=True)\n",
    "\n",
    "# Drop duplicates based on 'isbn' column\n",
    "final_books_dk = combined_df.drop_duplicates(subset='isbn')\n",
    "final_books_dk = combined_df.drop_duplicates(subset=['title', 'publisher', 'date'], keep='first')\n",
    "# Reset index of the new DataFrame\n",
    "final_books_dk.reset_index(drop=True, inplace=True)\n",
    "final_books_dk.drop(columns=['work', 'uri'], inplace=True)\n",
    "index_column = final_books_dk.columns.get_loc('Subtitle')\n",
    "\n",
    "# Move the column to position 2\n",
    "new_column_order = list(final_books_dk.columns)\n",
    "new_column_order.insert(1, new_column_order.pop(index_column))\n",
    "final_books_dk = final_books_dk[new_column_order]\n",
    "\n",
    "for i, date_value in enumerate(final_books_dk['date']):\n",
    "    # Convert integer to string before splitting\n",
    "    date_str = str(date_value)\n",
    "    # Split the date string by '-'\n",
    "    date_components = date_str.split('-')[0]\n",
    "    if '*' in date_components:\n",
    "        date_components = date_components.replace('*', '')  # Update here\n",
    "    # Update the 'date' column with the list of components\n",
    "    final_books_dk.at[i, 'date'] = date_components\n",
    "    \n",
    "for i in final_books_dk['Subtitle']:\n",
    "    if pd.isna(i):\n",
    "        final_books_dk['Subtitle'].replace({pd.NA: ''}, inplace=True)\n",
    "\n",
    "# Merge the values of 'title' and 'Subtitle' columns\n",
    "final_books_dk['title'] = final_books_dk['title'] + '. ' + final_books_dk['Subtitle']\n",
    "final_books_dk.drop(columns=['Subtitle'], inplace=True)\n",
    "\n",
    "\n",
    "final_books_dk.to_csv('bibliographic_data_DK.csv', index=False)\n",
    "final_books_dk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2.2 Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_books(query, max_results=40):\n",
    "    base_url = \"https://www.googleapis.com/books/v1/volumes\"\n",
    "    start_index = 0\n",
    "    all_results = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"startIndex\": start_index,\n",
    "            \"maxResults\": max_results\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            items = data.get(\"items\", [])\n",
    "            if not items:\n",
    "                break\n",
    "            all_results.extend(items)\n",
    "            start_index += max_results\n",
    "        else:\n",
    "            print(\"Failed to retrieve data. Status code:\", response.status_code)\n",
    "            break\n",
    "\n",
    "    return all_results\n",
    "\n",
    "books_k = fetch_books(\"Klimt\")\n",
    "\n",
    "# Saving JSON data to a file\n",
    "with open(\"klimt_books.json\", \"w\") as json_file:\n",
    "    json.dump(books_k, json_file, indent=4)\n",
    "\n",
    "print(\"JSON data saved to klimt_books.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON data from file\n",
    "with open(\"klimt_books.json\", \"r\") as json_file:\n",
    "    books_data_k = json.load(json_file)\n",
    "\n",
    "# Extract relevant fields from each book item\n",
    "books_list_k = []\n",
    "for book in books_data_k:\n",
    "    book_info = {\n",
    "        \"Title\": book[\"volumeInfo\"].get(\"title\", \"N/A\"),\n",
    "        \"Subtitle\": book[\"volumeInfo\"].get(\"subtitle\", \"N/A\"),\n",
    "        \"Authors\": \", \".join(book[\"volumeInfo\"].get(\"authors\", [\"N/A\"])),\n",
    "        \"Publisher\": book[\"volumeInfo\"].get(\"publisher\", \"N/A\"),\n",
    "        \"PublishedDate\": book[\"volumeInfo\"].get(\"publishedDate\", \"N/A\"),\n",
    "        \"isbn\": book[\"volumeInfo\"].get(\"industryIdentifiers\", [{}])[0].get(\"identifier\", \"N/A\"),  # Retrieving ISBN\n",
    "    }\n",
    "    books_list_k.append(book_info)\n",
    "\n",
    "# Create DataFrame\n",
    "books_df_k = pd.DataFrame(books_list_k)\n",
    "books_df_k.replace('N/A', np.nan, inplace= True)\n",
    "\n",
    "# Display DataFrame\n",
    "books_df_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking how many times \"Klimt\" appears in the title column\n",
    "liss = []\n",
    "for column_name in books_df_k.columns:\n",
    "    if column_name == \"Title\":\n",
    "        for value in books_df_k[column_name]:\n",
    "            if \"Klimt\" in value or \"Klimt\" in value:\n",
    "                liss.append(value)\n",
    "print(len(liss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_k = books_df_k[books_df_k[\"Title\"].str.contains(\"Klimt\", case=False)]\n",
    "\n",
    "books_k.reset_index(drop=True, inplace=True)\n",
    "\n",
    "books_k.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'ISBN' column\n",
    "df_combined_k= pd.merge(bnf_k, books_k, on='isbn', how='inner')\n",
    "\n",
    "# Display the new DataFrame with rows where ISBN is found in both DataFrames\n",
    "df_combined_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'Title' column in df2 to 'title'\n",
    "books_k.rename(columns={'Title': 'title'}, inplace=True)\n",
    "books_k.rename(columns={'PublishedDate': 'date'}, inplace=True)\n",
    "books_k.rename(columns={'Publisher': 'publisher'}, inplace=True)\n",
    "# Concatenate the DataFrames vertically\n",
    "combined_df = pd.concat([bnf_k, books_k], ignore_index=True)\n",
    "\n",
    "# Drop duplicates based on 'isbn' column\n",
    "final_books_k = combined_df.drop_duplicates(subset='isbn')\n",
    "final_books_k = combined_df.drop_duplicates(subset=['title', 'publisher', 'date'], keep='first')\n",
    "# Reset index of the new DataFrame\n",
    "final_books_k.reset_index(drop=True, inplace=True)\n",
    "final_books_k.drop(columns=['work', 'uri'], inplace=True)\n",
    "index_column = final_books_k.columns.get_loc('Subtitle')\n",
    "\n",
    "# Move the column to position 2\n",
    "new_column_order = list(final_books_k.columns)\n",
    "new_column_order.insert(1, new_column_order.pop(index_column))\n",
    "final_books_k = final_books_k[new_column_order]\n",
    "\n",
    "for i, date_value in enumerate(final_books_k['date']):\n",
    "    # Convert integer to string before splitting\n",
    "    date_str = str(date_value)\n",
    "    # Split the date string by '-'\n",
    "    date_components = date_str.split('-')[0]\n",
    "    if '*' in date_components:\n",
    "        date_components = date_components.replace('*', '')  # Update here\n",
    "    # Update the 'date' column with the list of components\n",
    "    final_books_k.at[i, 'date'] = date_components\n",
    "    \n",
    "for i in final_books_k['Subtitle']:\n",
    "    if pd.isna(i):\n",
    "        final_books_k['Subtitle'].replace({pd.NA: ''}, inplace=True)\n",
    "\n",
    "# Merge the values of 'title' and 'Subtitle' columns\n",
    "final_books_k['title'] = final_books_k['title'] + '. ' + final_books_k['Subtitle']\n",
    "final_books_k.drop(columns=['Subtitle'], inplace=True)\n",
    "\n",
    "final_books_k.to_csv('bibliographic_data_KLI.csv', index=False)\n",
    "# Display the new DataFrame with unique rows based on ISBN and consistent column name 'title'\n",
    "final_books_k.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Bibliography visualization\n",
    "### 2.2.1 Pubblications per year\n",
    "Here, we analyze the number of publications about the authors per year.\n",
    "**Research question**: How many publication about the author per year?\n",
    "\n",
    "#### 2.2.1.1 De Kooning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This code shows the plot of the above mentioned data.\n",
    "##To make the notebook lighter we live it as not automatically runned\n",
    "##To show it de comment the cell.\n",
    "\n",
    "\n",
    "# final_books_dk = final_books_dk.sort_values(by=\"date\")\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.histplot(data=final_books_dk, x=\"date\", color='#E97D01', kde=True, zorder = 4)\n",
    "\n",
    "# plt.title(\"Distribution of Publication per Years\", color='#352f36')  # Change title color\n",
    "# plt.xlabel(\"Year\", color='#352f36')  # Change xlabel color\n",
    "# plt.ylabel(\"Number of Publications\", color='#352f36')  # Change ylabel color\n",
    "# plt.xticks(rotation=45, color='#352f36')  # Change xticks color and rotation\n",
    "# plt.yticks(color='#352f36')  # Change yticks color\n",
    "\n",
    "# plt.grid(axis='y', linestyle='-', alpha=0.7, zorder = 0)  # Add horizontal grid\n",
    "# sns.despine(right=True, top=True)  # Remove top and right margin\n",
    "\n",
    "# plt.tight_layout()  # Adjust layout to prevent label overlap\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.2 Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This code shows the plot of the above mentioned data.\n",
    "##To make the notebook lighter we live it as not automatically runned\n",
    "##To show it de comment the cell.\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.histplot(data=final_books_k, x=\"date\", color='#26408B', kde=True, zorder = 4)\n",
    "\n",
    "# plt.title(\"Distribution of Publication per Years\", color='#352f36')  # Change title color\n",
    "# plt.xlabel(\"Year\", color='#352f36')  # Change xlabel color\n",
    "# plt.ylabel(\"Number of Publications\", color='#352f36')  # Change ylabel color\n",
    "# plt.xticks(rotation=45, color='#352f36')  # Change xticks color and rotation\n",
    "# plt.yticks(color='#352f36')  # Change yticks color\n",
    "\n",
    "# plt.grid(axis='y', linestyle='-', alpha=0.7, zorder = 0)  # Add horizontal grid\n",
    "# sns.despine(right=True, top=True)  # Remove top and right margin\n",
    "\n",
    "# plt.tight_layout()  # Adjust layout to prevent label overlap\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.3 Comparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram of publication per year\n",
    "from matplotlib.lines import Line2D\n",
    "# Concatenate the dataframes and add a 'category' column to differentiate between them\n",
    "run_final_books_k = final_books_k.copy()\n",
    "run_final_books_dk = final_books_dk.copy()\n",
    "run_final_books_k['category'] = 'Klimt'\n",
    "run_final_books_dk['category'] = 'De Kooning'\n",
    "combined_df = pd.concat([run_final_books_k, run_final_books_dk])\n",
    "\n",
    "# Sort the combined dataframe by date\n",
    "combined_df = combined_df.sort_values(by=\"date\")\n",
    "\n",
    "# Plot the combined histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=combined_df, x=\"date\", hue=\"category\", palette={'Klimt': '#26408B', 'De Kooning': '#E97D01'}, zorder=4)\n",
    "plt.title(\"Distribution of Publication Years\", color='#352f36')\n",
    "plt.xlabel(\"Year\", color='#352f36')\n",
    "plt.ylabel(\"Count\", color='#352f36')\n",
    "plt.xticks(rotation=45, color='#352f36')  # Rotate the x-axis tick labels by 45 degrees\n",
    "plt.yticks(color='#352f36')\n",
    "\n",
    "plt.grid(axis='y', linestyle='-', alpha=0.7, zorder=0)\n",
    "\n",
    "sns.despine(right=True, top=True)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent label overlap\n",
    "\n",
    "# Add custom legend\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#26408B', markersize=10, label='Klimt'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#E97D01', markersize=10, label='De Kooning')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper left', title='Artists')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's evident that Klimt garnered more interest starting from the 1990s. De Kooning's attention, on the other hand, remained highly variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('../docs/data/comparison_publication_per_year.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exhibition\n",
    "## 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section checks how many bibliographic records are actually in the exhibition catalogues. Since no type of publication or genre was specified/extracted from data, we manually recognized exhibition catalogues by extracting specific keywords from the title. \n",
    "\n",
    "### 3.1.1 De Kooning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows containing specified keywords in 'title', 'subtitle', or 'description' columns\n",
    "mask = final_books_dk['title'].str.contains(r'exhibition|exhib\\.|mostra|catalogue |catalogo|exposition|retrospective|Ausstellung', case=False, na=False) \n",
    "\n",
    "# Create the exhibitions DataFrame containing rows where keywords are present\n",
    "exhibitions_dataframe_dk = final_books_dk[mask]\n",
    "\n",
    "# Remove the rows where keywords are present from the original DataFrame\n",
    "dfbooks_dk = final_books_dk[~mask]\n",
    "\n",
    "# Reset index of the original DataFrame\n",
    "dfbooks_dk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reset index of the exhibitions DataFrame\n",
    "exhibitions_dataframe_dk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"\\nExhibitions DataFrame:\")\n",
    "exhibitions_dataframe_dk.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy library has been used in order to perform Name Entity Recognition over the titles of the exhibition catalogues, to extract exhibition locations. Retrieving this kind of data could be useful to understand where or in which specific venues exhibitions have taken place. In this case we have used the ‘en_core_web_sm’ dataset because it was the most accurate one among those that we tried to use. In fact, even though dataset data is multilingual, Spacy’s multilingual dataset did not perform well on our titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "# Process Text and Extract Location Names\n",
    "def extract_location(text):\n",
    "    doc = nlp(text)\n",
    "    locations = [entity.text for entity in doc.ents if entity.label_ == 'GPE']\n",
    "    return locations\n",
    "\n",
    "# Apply the extract_location function to the 'title' and 'Subtitle' columns and store the result in a new column 'locations'\n",
    "exhibitions_dataframe_dk['Exhibit locations'] = exhibitions_dataframe_dk.apply(lambda row: extract_location(row['title']), axis=1)\n",
    "\n",
    "# Convert the list of extracted locations into a comma-separated string\n",
    "exhibitions_dataframe_dk['Exhibit locations'] = exhibitions_dataframe_dk['Exhibit locations'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "exhibitions_dataframe_dk.to_csv('exhibitions_data_DK.csv', index=False)\n",
    "exhibitions_dataframe_dk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(final_books_dk)\n",
    "\n",
    "# Count rows where 'title', 'subtitle', or 'description' contain specified keywords\n",
    "keyword_rows = final_books_dk[final_books_dk['title'].str.contains(r'exhibition|exhib\\.|mostra|catalogue|catalogo|exposition|retrospective|Ausstellung', case=False, na=False)]\n",
    "\n",
    "# Get the count of rows containing the specified keywords\n",
    "keyword_rows_count_dk = len(keyword_rows)\n",
    "\n",
    "keyword_rows_not_count_dk = total_rows - keyword_rows_count_dk\n",
    "\n",
    "percentage_keyword_rows_k = (keyword_rows_count_dk / total_rows) * 100\n",
    "\n",
    "percentage_not_keyword_rows_k = ((keyword_rows_count_dk) /total_rows)* 100\n",
    "\n",
    "data = {\n",
    "    'key': ['not exhibition', 'exhibition'],\n",
    "    'count': [keyword_rows_not_count_dk, keyword_rows_count_dk],\n",
    "    'percentage': [percentage_not_keyword_rows_k, percentage_keyword_rows_k]\n",
    "}\n",
    "\n",
    "total_count = keyword_rows_not_count_dk + keyword_rows_count_dk\n",
    "total_percentage = 100\n",
    "\n",
    "total_row = pd.DataFrame({'key': ['Total'], 'count': [total_count], 'percentage': [total_percentage]})\n",
    "\n",
    "# Create the DataFrame\n",
    "count_exhib_percentage_dk = pd.DataFrame(data)\n",
    "\n",
    "# Concatenate the total row DataFrame with the existing DataFrame\n",
    "count_exhib_percentage_dk = pd.concat([count_exhib_percentage_dk, total_row], ignore_index=True)\n",
    "count_exhib_percentage_dk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = len(final_books_k)\n",
    "\n",
    "# Count rows where 'title', 'subtitle', or 'description' contain specified keywords\n",
    "keyword_rows = final_books_k[final_books_k['title'].str.contains(r'exhibition|exhib\\.|mostra|catalogue|catalogo|exposition|retrospective|Ausstellung', case=False, na=False)]\n",
    "\n",
    "# Get the count of rows containing the specified keywords\n",
    "keyword_rows_count_k = len(keyword_rows)\n",
    "\n",
    "keyword_rows_not_count_k = total_rows - keyword_rows_count_k\n",
    "\n",
    "percentage_keyword_rows_k = (keyword_rows_count_k / total_rows) * 100\n",
    "\n",
    "percentage_not_keyword_rows_k = ((keyword_rows_count_k) /total_rows)* 100\n",
    "\n",
    "data = {\n",
    "    'key': ['not exhibition', 'exhibition'],\n",
    "    'count': [keyword_rows_not_count_k, keyword_rows_count_k],\n",
    "    'percentage': [percentage_not_keyword_rows_k, percentage_keyword_rows_k]\n",
    "}\n",
    "\n",
    "total_count = keyword_rows_not_count_k + keyword_rows_count_k\n",
    "total_percentage = 100\n",
    "\n",
    "total_row = pd.DataFrame({'key': ['Total'], 'count': [total_count], 'percentage': [total_percentage]})\n",
    "\n",
    "# Create the DataFrame\n",
    "count_exhib_percentage_k = pd.DataFrame(data)\n",
    "\n",
    "# Concatenate the total row DataFrame with the existing DataFrame\n",
    "count_exhib_percentage_k = pd.concat([count_exhib_percentage_k, total_row], ignore_index=True)\n",
    "count_exhib_percentage_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your original DataFrame\n",
    "\n",
    "# Create a mask for rows containing specified keywords in 'title', 'subtitle', or 'description' columns\n",
    "mask = final_books_k['title'].str.contains(r'exhibition|exhib\\.|mostra|catalogue |catalogo|exposition|retrospective|Ausstellung', case=False, na=False) \n",
    "\n",
    "# Create the exhibitions DataFrame containing rows where keywords are present\n",
    "exhibitions_dataframe_k = final_books_k[mask]\n",
    "\n",
    "# Remove the rows where keywords are present from the original DataFrame\n",
    "dfbooks_k = final_books_k[~mask]\n",
    "\n",
    "# Reset index of the original DataFrame\n",
    "dfbooks_k.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Reset index of the exhibitions DataFrame\n",
    "exhibitions_dataframe_k.reset_index(drop=True, inplace=True)\n",
    "exhibitions_dataframe_k.to_csv('exhibitions_data_KLI.csv', index=False)\n",
    "\n",
    "# Display the exhibitions DataFrame containing rows where keywords are present\n",
    "print(\"\\nExhibitions DataFrame:\")\n",
    "exhibitions_dataframe_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_location(text):\n",
    "    doc = nlp(text)\n",
    "    locations = [entity.text for entity in doc.ents if entity.label_ == 'GPE']\n",
    "    return locations\n",
    "\n",
    "\n",
    "# Apply the extract_location function to the 'title' and  columns and store the result in a new column 'locations'\n",
    "exhibitions_dataframe_k['Exhibit locations'] = exhibitions_dataframe_k.apply(lambda row: extract_location(row['title'] ), axis=1)\n",
    "\n",
    "# Convert the list of extracted locations into a comma-separated string\n",
    "exhibitions_dataframe_k['Exhibit locations'] = exhibitions_dataframe_k['Exhibit locations'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "exhibitions_dataframe_k.to_csv('exhibitions_data_KLI.csv', index=False)\n",
    "exhibitions_dataframe_k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Distribtion of exhibition catalogue over materials\n",
    "\n",
    "Here, we examine how many of our extracted data from the web pertain to exhibitions catalogue.\n",
    "\n",
    "**Research question**: What is the distribution and the percentage of data extracted that are catalogues?\n",
    "\n",
    "#### 3.2.1.1 De Kooning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This code shows the plot of the above mentioned data.\n",
    "##To make the notebook lighter we live it as not automatically runned\n",
    "##To show it de comment the cell.\n",
    "\n",
    "# Plot the percentage of exhibition in data extracted online\n",
    "# # settings\n",
    "# sizes = [keyword_rows_count_dk, keyword_rows_not_count_dk]\n",
    "# labels = ['Exhibitions', 'Not Exhibition']\n",
    "# colors = ['#B53302','#E97D01']\n",
    "# # explode = [0, 0.1]\n",
    "# # Create a pieplot\n",
    "# plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=0, pctdistance=0.5)\n",
    "\n",
    "# # add a circle at the center to transform it in a donut chart\n",
    "# my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "# p=plt.gcf()\n",
    "# p.gca().add_artist(my_circle)\n",
    "# plt.title('Distribution of Exhibition in online data - De Kooning', color = '#352f36')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This code shows the plot of the above mentioned data.\n",
    "##To make the notebook lighter we live it as not automatically runned\n",
    "##To show it de comment the cell.\n",
    "\n",
    "# Plot the percentage of exhibition in data extracted online\n",
    "# # settings\n",
    "# sizes = [keyword_rows_count_k, keyword_rows_not_count_k]\n",
    "# labels = ['Exhibitions', 'Not Exhibition']\n",
    "# colors = ['#0F084B','#26408B']\n",
    "# # Create a pieplot\n",
    "# plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=0, pctdistance=0.5, textprops={'color': '#352f36'})\n",
    "# # add a circle at the center to transform it in a donut chart\n",
    "# my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "# p=plt.gcf()\n",
    "# p.gca().add_artist(my_circle)\n",
    "# plt.title('Distribution of Exhibition in online data - Klimt', color = '#352f36')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.3 Comparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the percentage of exhibition in data extracted online\n",
    "\n",
    "# Create subplots with 1 row and 2 columns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot for De Kooning\n",
    "sizes_dk = [keyword_rows_count_dk, keyword_rows_not_count_dk]\n",
    "labels_dk = ['Exhibitions', 'Not Exhibition']\n",
    "colors_dk = ['#B53302', '#E97D01']\n",
    "axes[0].pie(sizes_dk, labels=labels_dk, colors=colors_dk, autopct='%1.1f%%', startangle=0, pctdistance=0.5, textprops={'color': '#352f36'})\n",
    "axes[0].add_artist(plt.Circle((0, 0), 0.7, color='white'))\n",
    "axes[0].set_title('Distribution of Exhibition in online data - De Kooning', color='#352f36')\n",
    "\n",
    "# Plot for Klimt\n",
    "sizes_k = [keyword_rows_count_k, keyword_rows_not_count_k]\n",
    "labels_k = ['Exhibitions', 'Not Exhibition']\n",
    "colors_k = ['#0F084B', '#26408B']\n",
    "axes[1].pie(sizes_k, labels=labels_k, colors=colors_k, autopct='%1.1f%%', startangle=0, pctdistance=0.5, textprops={'color': '#352f36'})\n",
    "axes[1].add_artist(plt.Circle((0, 0), 0.7, color='white'))\n",
    "axes[1].set_title('Distribution of Exhibition in online data - Klimt', color='#352f36')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data\n",
    "categories = ['De Kooning', 'Klimt']\n",
    "exhibition_counts = [keyword_rows_count_dk, keyword_rows_count_k]\n",
    "not_exhibition_counts = [keyword_rows_not_count_dk, keyword_rows_not_count_k]\n",
    "\n",
    "# Define colors\n",
    "exhibition_colors = ['#B53302', '#0F084B']\n",
    "not_exhibition_colors = ['#E97D01', '#26408B']\n",
    "\n",
    "# Create stacked bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(categories))\n",
    "\n",
    "# Plot the bars for 'Exhibition'\n",
    "bars_exhibition = plt.bar(index, exhibition_counts, color=exhibition_colors, label='Exhibition')\n",
    "\n",
    "# Plot the bars for 'Not Exhibition' on top of 'Exhibition'\n",
    "bars_not_exhibition = plt.bar(index, not_exhibition_counts, color=not_exhibition_colors, bottom=exhibition_counts, label='Not Exhibition')\n",
    "\n",
    "# Add value labels for each bar\n",
    "for i in range(len(categories)):\n",
    "    plt.text(index[i], exhibition_counts[i] / 2, str(exhibition_counts[i]), color='white', ha='center', va='center')\n",
    "    plt.text(index[i], exhibition_counts[i] + not_exhibition_counts[i] / 2, str(not_exhibition_counts[i]), color='white', ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Artists', color='#352f36')  # Change xlabel color\n",
    "plt.ylabel('Number of Items', color='#352f36')  # Change ylabel color\n",
    "plt.title('Distribution of Exhibition in online data', color='#352f36')  # Change title color\n",
    "plt.xticks(index, categories, color='#352f36')  # Change xticks color\n",
    "plt.yticks(color='#352f36')  # Change yticks color\n",
    "\n",
    "# Create custom legend for both sets of bars\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='#B53302', lw=10, label='Exhibition De Kooning'),\n",
    "    Line2D([0], [0], color='#E97D01', lw=10, label='Not Exhibition De Kooning'),\n",
    "    Line2D([0], [0], color='#0F084B', lw=10, label='Exhibition Klimt'),\n",
    "    Line2D([0], [0], color='#26408B', lw=10, label='Not Exhibition Klimt')\n",
    "]\n",
    "legend = plt.legend(handles=legend_elements, loc='upper left')\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('#352f36')  # Set legend label color\n",
    "\n",
    "# Remove top and right margin\n",
    "sns.despine(right=True, top=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relatively consistent amount of data prompts us to consider that some patterns or insights might emerge despite the limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Exhibitions per year\n",
    "\n",
    "Here, we observe the number of exhibitions per year for one artist.\n",
    "\n",
    "**Research question**: How many exhibitons per year of each?\n",
    "#### 3.2.2.1 De Kooning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'date' is the column name and exhibitions_dataframe_k is your DataFrame\n",
    "date_counts_dk = exhibitions_dataframe_dk.groupby('date').size().reset_index(name='count')\n",
    "date_counts_dk = date_counts_dk.sort_values(by='date')\n",
    "\n",
    "# Display the DataFrame\n",
    "date_counts_dk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This code shows the plot of the above mentioned data.\n",
    "##To make the notebook lighter we live it as not automatically runned\n",
    "##To show it de comment the cell.\n",
    "\n",
    "# #Plot exhhibition over time\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(data=date_counts_dk, x='date', y='count', color='#E97D01')\n",
    "# plt.title('Exhibitions Count Over Time', color='#352f36')  # Change title color\n",
    "# plt.xlabel('Date', color='#352f36')  # Change xlabel color\n",
    "# plt.ylabel('Count', color='#352f36')  # Change ylabel color\n",
    "# plt.xticks(rotation=45, color='#352f36')  # Change xticks color and rotation\n",
    "# plt.yticks(color='#352f36')  # Change yticks color\n",
    "\n",
    "# sns.despine(right=True, top=True)  # Remove top and right margin\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.2 Klimt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'date' is the column name and exhibitions_dataframe_k is your DataFrame\n",
    "date_counts_k = exhibitions_dataframe_k.groupby('date').size().reset_index(name='count')\n",
    "date_counts_k = date_counts_k.sort_values(by='date')\n",
    "\n",
    "# Display the DataFrame\n",
    "date_counts_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This code shows the plot of the above mentioned data.\n",
    "##To make the notebook lighter we live it as not automatically runned\n",
    "##To show it de comment the cell.\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(data=date_counts_k, x='date', y='count', color='#26408B')\n",
    "# plt.title('Exhibitions Count Over Time', color='#352f36')  # Change title color\n",
    "# plt.xlabel('Date', color='#352f36')  # Change xlabel color\n",
    "# plt.ylabel('Count', color='#352f36')  # Change ylabel color\n",
    "# plt.xticks(rotation=45, color='#352f36')  # Change xticks color and rotation\n",
    "# plt.yticks(color='#352f36')  # Change yticks color\n",
    "\n",
    "# sns.despine(right=True, top=True)  # Remove top and right margin\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2.3 Comparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Outer merge the DataFrames on the 'date' column\n",
    "merged_df = pd.merge(date_counts_dk, date_counts_k, on='date', how='outer')\n",
    "\n",
    "# Rename the count columns\n",
    "merged_df.rename(columns={'count_x': 'Exhibitions De Kooning', 'count_y': 'Exhibitions Klimt'}, inplace=True)\n",
    "\n",
    "# Sort by 'date'\n",
    "merged_df.sort_values(by='date', inplace=True)\n",
    "\n",
    "sns.lineplot(data=merged_df, x='date', y='Exhibitions De Kooning', color='#26408B', label='Exhibitions De Kooning')\n",
    "sns.lineplot(data=merged_df, x='date', y='Exhibitions Klimt', color='#FF5733', label='Exhibitions Klimt')\n",
    "\n",
    "plt.title('Exhibitions Count Over Time', color='#352f36')  # Change title color\n",
    "plt.xlabel('Year', color='#352f36')  # Change xlabel color\n",
    "plt.ylabel('Number of Exhibitions', color='#352f36')  # Change ylabel color\n",
    "plt.xticks(rotation=45, color='#352f36')  # Change xticks color and rotation\n",
    "plt.yticks(color='#352f36')  # Change yticks color\n",
    "\n",
    "sns.despine(right=True, top=True)  # Remove top and right margin\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The available data is quite limited, making it challenging to extract meaningful insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../docs/data/comparison_exhibition_per_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Publication and Exhibitions per Year\n",
    "Here we explore the relationship between data coming from section bibliography and exhibitions\n",
    "**Research question**: How many publication and Exhibition per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhibitions per year\n",
    "\n",
    "exhibtion_date_count = date_counts_dk.sort_values(by=\"date\")\n",
    "exhibtion_date_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_books_dk\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Drop rows with 'nan' strings in the 'date' column\n",
    "final_books_dk = final_books_dk[final_books_dk['date'] != 'nan']\n",
    "\n",
    "# Convert the \"date\" column to integers\n",
    "final_books_dk['date'] = final_books_dk['date'].astype(int)\n",
    "\n",
    "# Count the values in the 'date' column\n",
    "date_counts = final_books_dk['date'].value_counts().reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "date_counts.columns = ['date', 'count']\n",
    "\n",
    "publication_date_count = date_counts.sort_values(by=\"date\")\n",
    "publication_date_count.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge publication_date_count and exhibition_date count\n",
    "# Merge the DataFrames on the 'year' column\n",
    "# Convert columns to integers if they are not already\n",
    "publication_date_count['date'] = publication_date_count['date'].astype(int)\n",
    "exhibtion_date_count['date'] = exhibtion_date_count['date'].astype(int)\n",
    "\n",
    "# Merge the DataFrames on the 'year' column\n",
    "merged_data = pd.merge(publication_date_count, exhibtion_date_count, on='date', suffixes=('_publication', '_exhibition'), how='inner')\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "\n",
    "merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RICONTROLLA\n",
    "# Plotting histograms for count of exhibitions and count of publications on the same graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram for count of exhibitions\n",
    "plt.hist(merged_data['date'], bins=merged_data['date'].nunique(), weights=merged_data['count_exhibition'], color='blue', alpha=0.7, label='Exhibitions')\n",
    "\n",
    "# Plot histogram for count of publications\n",
    "plt.hist(merged_data['date'], bins=merged_data['date'].nunique(), weights=merged_data['count_publication'], color='orange', alpha=0.7, label='Publications')\n",
    "\n",
    "plt.title('Exhibitions and Publications Count Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be no clear correlation between the frequency of exhibitions and publications over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. De Kooning - a \"ground truth\" case\n",
    "\n",
    "It exists a web site of De Kooning storing many data about this author, between this also exhibitions and publications. Therefore, we decided to use it as a \"Ground truth\", a dataset that can be compared with the data extracted from the web to see how much they and our approach can be trusted.\n",
    "## 4.1 Data Mining\n",
    "### Complete list of De Kooning's one-man exibitions. \n",
    "In our research we considered also the number of exibitions and the venue of the exibitions as parameters in order to check whether the reputation of the artist has changed over the years. However, no complete dataset on artists' exhibitions was found. In order to get an idea on how many exibitions have been covered on catalogues, and, in particular, how many exhibitions are traced by bibliographic records on BnF and Gallica, we needed a \"ground truth\" to state if those sources of information could be somehow comprehensive. \n",
    "\n",
    "The case study is Willem de Kooning, since all data about exibitions are uploaded on the website of the Willem de Kooning Foundation. \n",
    "The result of the webscraping are shown here, with a total of 131 exhibitions, 81 possess a catalogue. \n",
    "\n",
    "In bibliography_DK.ipynb extraction from SPARQL endpoint of BnF and Google Books API has been done in order to get all bibliographic records on De Kooning - 31 of them are records on exhibitions. So 39% of exibitions with catalogue are present in that dataset, 23% of the total exhibitions are covered. There's also the need to say that the bibliographic records extracted do not concern only one-man shows, so they include further shows that are not present in the dataset reported here below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Exhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "URLs = [\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1940',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1950',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1960',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1970',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1980',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/1990',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/2000',\n",
    "    'https://www.dekooning.org/the-artist/exhibitions/past/one-man/2010'\n",
    "] \n",
    "\n",
    "titles_list = []\n",
    "\n",
    "for url in URLs: \n",
    "    req = requests.get(url) \n",
    "    soup = bs(req.text, 'html.parser') \n",
    "    \n",
    "    titles = soup.find_all('p', class_=\"unit_title spacing_03\") \n",
    "    \n",
    "    for title in titles:\n",
    "        titles_list.append(title.text.strip().replace(\"\\xa0\\n\", \";\").replace(\"\\xa0\", \";\").replace('\\n',';'))\n",
    "\n",
    "\n",
    "titles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    \"Inc.\": \"Inc.\",\n",
    "    \"and\": \"and\",\n",
    "    \"Science\": \"Science\",\n",
    "    \"Ontario\": \"\",\n",
    "    \"The\": \"The\",\n",
    "    \"Palazzo\": \"Palazzo\",\n",
    "    \"Droll\": \"Droll\",\n",
    "    \"Fourcade\": \" Fourcade\",\n",
    "    \"University\": \"University\",\n",
    "    \"Ishibashi\": \"Ishibashi\",\n",
    "    \"Smithsonian\": \"Smithsonian\",\n",
    "    \"Millbrook\": \"Millbrook\",\n",
    "    \"Seattle\": \" Seattle\",\n",
    "    \"World\": \"World\",\n",
    "    \"Carnegie\": \"Carnegie\",\n",
    "    \"Akademie \": \"Akademie \",\n",
    "    \"Berkeley\": \"Berkeley\",\n",
    "    \"Wellesley\": \"Wellesley\",\n",
    "    \"Mitchell-Innes\": \"Mitchell-Innes\",\n",
    "    \"Art\": \"Art\",\n",
    "    \"Colorado\": \"Colorado\"\n",
    "}\n",
    "\n",
    "new_list = []\n",
    "\n",
    "# Iterate through each string in the original list\n",
    "for item in titles_list:\n",
    "    # Replace ';(' with ' ('\n",
    "    item = item.replace(';(', ' (')\n",
    "    \n",
    "    # Find the index of the first occurrence of \"catalogue.\" or \"brochure.\"\n",
    "    catalogue_index = item.find(\"catalogue.\")\n",
    "    brochure_index = item.find(\"brochure.\")\n",
    "    \n",
    "    # Determine the index of the first occurrence among \"catalogue.\" and \"brochure.\"\n",
    "    if catalogue_index != -1 and brochure_index != -1:\n",
    "        first_occurrence_index = min(catalogue_index, brochure_index)\n",
    "    elif catalogue_index != -1:\n",
    "        first_occurrence_index = catalogue_index\n",
    "    elif brochure_index != -1:\n",
    "        first_occurrence_index = brochure_index\n",
    "    else:\n",
    "        first_occurrence_index = len(item)\n",
    "    \n",
    "    # Slice the string up to the first occurrence\n",
    "    item = item[:first_occurrence_index + len(\"catalogue.\")]\n",
    "    \n",
    "    parts = item.split(';')\n",
    "\n",
    "    if len(parts) == 2:\n",
    "        second_part = parts[1]\n",
    "        # Iterate through each keyword in the replacements dictionary\n",
    "        for keyword, replacement in replacements.items():\n",
    "            if \", \" in second_part and keyword in second_part:\n",
    "                # Get the index of the keyword\n",
    "                keyword_index = second_part.index(keyword)\n",
    "                # Get the index of the last \", \" before the keyword\n",
    "                comma_index = second_part.rfind(\", \", 0, keyword_index)\n",
    "                # Replace \", \" with \" \" before the keyword\n",
    "                if comma_index != -1:  # Ensure \", \" was found before the keyword\n",
    "                    second_part = second_part[:comma_index] + \" \" + second_part[comma_index + 2:]\n",
    "                # Replace the keyword with the corresponding replacement\n",
    "                second_part = second_part.replace(keyword, replacement)\n",
    "        # Split the second part (after ';') by ','\n",
    "        second_parts = second_part.split(',')\n",
    "        # Remove the third element if the length is greater than 5\n",
    "        if len(second_parts) > 5:\n",
    "            del second_parts[1]\n",
    "        # Create a sublist with the first part and the second parts\n",
    "        sublist = [parts[0]] + second_parts\n",
    "        # Append the sublist to the new list\n",
    "        new_list.append(sublist)\n",
    "\n",
    "print(new_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Initialize empty lists for each column\n",
    "exhibition = []\n",
    "venue = []\n",
    "city = []\n",
    "state = []\n",
    "date = []\n",
    "catalogue = []\n",
    "\n",
    "# Populate the lists from the data in x\n",
    "for i in new_list:\n",
    "    if len(i) >= 6:\n",
    "        exhibition.append(i[0])\n",
    "        venue.append(i[1])\n",
    "        city.append(i[2])\n",
    "        state.append(i[3])\n",
    "        date.append(i[4])\n",
    "        catalogue.append(i[5])\n",
    "\n",
    "\n",
    "exhibition_one_date_df_website = pd.DataFrame(columns=[\"Exhibition_name\", \"Venue\", \"City\", 'State', 'date', 'catalogue'])\n",
    "\n",
    "exhibition_one_date_df_website['Exhibition_name'] = exhibition\n",
    "exhibition_one_date_df_website['Venue'] = venue\n",
    "exhibition_one_date_df_website['City'] = city\n",
    "exhibition_one_date_df_website['State'] = state\n",
    "exhibition_one_date_df_website['date'] = date\n",
    "exhibition_one_date_df_website['catalogue'] = catalogue\n",
    "\n",
    "for i, item in enumerate(exhibition_one_date_df_website['catalogue']): #modificato oggi\n",
    "    if \".\" in item:\n",
    "        x = item.split('.')\n",
    "        exhibition_one_date_df_website.at[i, 'catalogue'] = x[0]\n",
    "\n",
    "exhibition_one_date_df_website.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i, item in enumerate(exhibition_one_date_df_website['date']):\n",
    "\n",
    "    parts = item.strip('()').split(' to ')\n",
    "    modified_dates = []\n",
    "    for date_str in parts:\n",
    "        if \"??/??\" in date_str:\n",
    "            month_and_year = date_str.split('/')[-1]  # Extract month and year\n",
    "            modified_date = \"01/01/\" + month_and_year  # Replace day with \"01\"\n",
    "            modified_dates.append(modified_date)\n",
    "        elif '??' in date_str:\n",
    "            month_and_year = date_str.split('/')[0] + '/01/' + date_str.split('/')[-1]\n",
    "            modified_dates.append(month_and_year)\n",
    "        else:\n",
    "            modified_dates.append(date_str)\n",
    "    exhibition_one_date_df_website.at[i, 'date'] = ' to '.join(modified_dates)\n",
    "    \n",
    "\n",
    "def extract_starting_range(date_str):\n",
    "    # Split the date range string by ' to ' or '-'\n",
    "    dates = date_str.strip('( )').split(' to ')\n",
    "    if len(dates) == 1:  # If ' to ' is not found, try splitting by '-'\n",
    "        dates = date_str.strip('( )').split('\\u2013')\n",
    "    if len(dates) < 2:\n",
    "        return None  \n",
    "    \n",
    "    starting_date = dates[0]\n",
    "    \n",
    "    # Convert the starting date to datetime format and extract the date part\n",
    "    return pd.to_datetime(starting_date, errors='coerce').date()\n",
    "\n",
    "\n",
    "def extract_ending_range(date_str):\n",
    "    dates = date_str.strip('( )').split(' to ')\n",
    "    if len(dates) == 1:  # If ' to ' is not found, try splitting by '-'\n",
    "        dates = date_str.strip('( )').split('\\u2013')\n",
    "    if len(dates) < 2:\n",
    "        return None  \n",
    "    ending_date = dates[1]\n",
    "    \n",
    "    # Convert the ending date to datetime format and extract the date part\n",
    "    return pd.to_datetime(ending_date, errors='coerce').date()\n",
    "\n",
    "exhibition_df_website = exhibition_one_date_df_website.copy()\n",
    "# Apply the function to the 'date' column to create a new column with datetime objects\n",
    "exhibition_df_website['startingdate'] = exhibition_df_website['date'].apply(extract_starting_range)\n",
    "exhibition_df_website['endingdate'] = exhibition_df_website['date'].apply(extract_ending_range)\n",
    "\n",
    "\n",
    "\n",
    "exhibition_df_website.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# df.drop('date', axis=1, inplace=True)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "exhibition_df_website.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Monograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup as bs \n",
    "\n",
    "URLs = [\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1950',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1960',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1970',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1980',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/1990',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/2000',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/2010',\n",
    "    'https://www.dekooning.org/the-artist/bibliography/monographs/2020'\n",
    "] \n",
    "\n",
    "titles_li = []\n",
    "\n",
    "for url in URLs: \n",
    "    req = requests.get(url) \n",
    "    soup = bs(req.text, 'html.parser') \n",
    "    \n",
    "    titles = soup.find_all('div', class_=\"unit_copy spacing_03\") \n",
    "    \n",
    "    for title in titles:\n",
    "        titles_li.append(title.text.strip().replace(\"\\xa0\\n\", \";\").replace(\"\\xa0\", \";\").replace('\\n',';').replace('\\t', '').replace(':;;', ': ').replace(\";;With\", \" With\")) \n",
    "\n",
    "titles_li\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "new_li = []\n",
    "\n",
    "# Iterate through each string in the original list\n",
    "for item in titles_li:\n",
    "\n",
    "# Split the string 'item' using either ';;' or ', 1' as the delimiter\n",
    "    parts = re.split(r';;|; ;', item)\n",
    "\n",
    "    new_li.append(parts)\n",
    "\n",
    "print(new_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Initialize empty lists for each column\n",
    "author = []\n",
    "title = []\n",
    "type = []\n",
    "publisher = []\n",
    "date = []\n",
    "\n",
    "# Populate the lists from the data in x\n",
    "for i in new_li:\n",
    "    if len(i) == 5:\n",
    "        author.append(i[0])\n",
    "        title.append(i[1])\n",
    "        if 'Exh.' in  i[2]  or 'PhD ' in i[2] or 'Series' in i[2]:\n",
    "            type.append(i[2])\n",
    "        else:\n",
    "            type.append('')\n",
    "        publisher.append(i[3])\n",
    "        date.append(i[4])\n",
    "    elif len(i) ==4:\n",
    "        if 'de Kooning' in i[1]:\n",
    "            author.append(i[0])\n",
    "            title.append(i[1])\n",
    "            type.append('')\n",
    "            publisher.append(i[2])\n",
    "            date.append(i[3])\n",
    "        elif 'de Kooning' in i[0] :\n",
    "            author.append('')\n",
    "            title.append(i[0])\n",
    "            type.append(i[1])\n",
    "            publisher.append(i[2])\n",
    "            date.append(i[3])\n",
    "        \n",
    "        \n",
    "\n",
    "# Create DataFrame\n",
    "pubblication_df_website = pd.DataFrame({\"author\": author, \"title\": title, \"type\": type, 'publisher': publisher, 'date': date})\n",
    "pubblication_df_website['publisher'] = pubblication_df_website['publisher'].str.split(',').str[0]\n",
    "pubblication_df_website['date'] = pubblication_df_website['date'].str.extract(r'(\\d{4})')\n",
    "\n",
    "pubblication_df_website.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Visualization\n",
    "In this section we try to see the actual representativeness of the data extracted from the web for what concers the publications and the exhibition catalogues of De Kooning. The specific **reserch questions** will be:\n",
    "\n",
    "- How many Exhibitions catalogue are in the web site? How much this value differs from the data obtained?\n",
    "\n",
    "\n",
    "### 4.2.1 Different coverage of Data\n",
    "\n",
    "We already calculated the value of data on web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code shows the plot of the above mentioned data.\n",
    "#To make the notebook lighter we live it as not automatically runned\n",
    "#To show it de comment the cell.\n",
    "\n",
    "# # Plot the percentage of exhibition in data extracted online\n",
    "# # settings\n",
    "# sizes = [keyword_rows_count_dk, keyword_rows_not_count_dk]\n",
    "# labels = ['Exhibitions', 'Not Exhibition']\n",
    "# colors = ['#B53302','#E97D01']\n",
    "# # explode = [0, 0.1]\n",
    "# # Create a pieplot\n",
    "# plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=0, pctdistance=0.5)\n",
    "\n",
    "# # add a circle at the center to transform it in a donut chart\n",
    "# my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "# p=plt.gcf()\n",
    "# p.gca().add_artist(my_circle)\n",
    "# plt.title('Distribution of Exhibition in online data - De Kooning', color = '#352f36')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the same calculation on data coming from the web site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of  catalogue in bibliographic data\n",
    "# Filter rows where 'type' is 'exh.cat'\n",
    "exh_cat_df = pubblication_df_website[pubblication_df_website['type'] == 'Exh. cat.']\n",
    "\n",
    "# Count of all other rows\n",
    "other_count = len(pubblication_df_website) - len(exh_cat_df)\n",
    "\n",
    "# Create a new DataFrame with counts\n",
    "exhibition_in_bibl_count_df = pd.DataFrame({'type': ['Exh. cat.', 'others'], 'count': [len(exh_cat_df), other_count]})\n",
    "\n",
    "# Display the result DataFrame\n",
    "exhibition_in_bibl_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhibitions in web\n",
    "exhibitions_in_site = exhibition_in_bibl_count_df['count'][0]\n",
    "other_in_site = exhibition_in_bibl_count_df['count'][1]\n",
    "\n",
    "exhibitions_in_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code shows the plot of the above mentioned data.\n",
    "#To make the notebook lighter we live it as not automatically runned\n",
    "#To show it de comment the cell.\n",
    "\n",
    "# # settings\n",
    "# sizes = [exhibitions_in_site, other_in_site]\n",
    "# labels = ['Exhibitions cat. in website', 'Other texts']\n",
    "# colors = ['#B53302','#E97D01']\n",
    "# # explode = [0, 0.1]\n",
    "# # Create a pieplot\n",
    "# plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=0, pctdistance=0.5, textprops={'color': '#352f36'})\n",
    "\n",
    "# # add a circle at the center to transform it in a donut chart\n",
    "# my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
    "# p=plt.gcf()\n",
    "# p.gca().add_artist(my_circle)\n",
    "# plt.title('Distribution of Exhibition in Foundation data', color = '#352f36')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the percentage of exhibition in data extracted online\n",
    "\n",
    "# Create subplots with 1 row and 2 columns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot for De Kooning\n",
    "sizes_dk = [keyword_rows_count_dk, keyword_rows_not_count_dk]\n",
    "labels_dk = ['Exhibitions', 'Not Exhibition']\n",
    "colors_dk = ['#B53302', '#E97D01']\n",
    "axes[0].pie(sizes_dk, labels=labels_dk, colors=colors_dk, autopct='%1.1f%%', startangle=0, pctdistance=0.5, textprops={'color': '#352f36'})\n",
    "axes[0].add_artist(plt.Circle((0, 0), 0.7, color='white'))\n",
    "axes[0].set_title('Distribution of Exhibition in online data - De Kooning', color='#352f36')\n",
    "\n",
    "# Plot for Klimt\n",
    "sizes_k = sizes = [exhibitions_in_site, other_in_site]\n",
    "labels_k = ['Exhibitions cat. in website', 'Other texts']\n",
    "colors_k = ['#B53302', '#E97D01']\n",
    "axes[1].pie(sizes_k, labels=labels_k, colors=colors_k, autopct='%1.1f%%', startangle=0, pctdistance=0.5, textprops={'color': '#352f36'})\n",
    "axes[1].add_artist(plt.Circle((0, 0), 0.7, color='white'))\n",
    "axes[1].set_title('Distribution of Exhibition in Foundation data', color='#352f36')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data\n",
    "categories = ['Web scraping', 'De Kooning Foundation']\n",
    "exhibition_counts = [keyword_rows_count_dk, exhibitions_in_site]\n",
    "not_exhibition_counts = [keyword_rows_not_count_dk, other_in_site]\n",
    "\n",
    "# Define colors\n",
    "exhibition_colors = ['#B53302', '#B53302']\n",
    "not_exhibition_colors = ['#E97D01', '#E97D01']\n",
    "\n",
    "# Create stacked bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(categories))\n",
    "\n",
    "# Plot the bars for 'Exhibition'\n",
    "bars_exhibition = plt.bar(index, exhibition_counts, color=exhibition_colors, label='Exhibition')\n",
    "\n",
    "# Plot the bars for 'Not Exhibition' on top of 'Exhibition'\n",
    "bars_not_exhibition = plt.bar(index, not_exhibition_counts, color=not_exhibition_colors, bottom=exhibition_counts, label='Not Exhibition')\n",
    "\n",
    "# Add value labels for each bar\n",
    "for i in range(len(categories)):\n",
    "    plt.text(index[i], exhibition_counts[i] / 2, str(exhibition_counts[i]), color='white', ha='center', va='center')\n",
    "    plt.text(index[i], exhibition_counts[i] + not_exhibition_counts[i] / 2, str(not_exhibition_counts[i]), color='white', ha='center', va='center')\n",
    "\n",
    "plt.xlabel('Web scraping vs. Website', color='#352f36')  # Change xlabel color\n",
    "plt.ylabel('Number of Items', color='#352f36')  # Change ylabel color\n",
    "plt.title('Distribution of Exhibition in online data and De Kooning Foundation website', color='#352f36')  # Change title color\n",
    "plt.xticks(index, categories, color='#352f36')  # Change xticks color\n",
    "plt.yticks(color='#352f36')  # Change yticks color\n",
    "\n",
    "# Create custom legend for both sets of bars\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='#B53302', lw=10, label='Exhibition webscraping'),\n",
    "    Line2D([0], [0], color='#E97D01', lw=10, label='Not Exhibition  webscraping'),\n",
    "    Line2D([0], [0], color='#B53302', lw=10, label='Exhibition De Kooning Foundation'),\n",
    "    Line2D([0], [0], color='#E97D01', lw=10, label='Not Exhibition Foundation')\n",
    "]\n",
    "legend = plt.legend(handles=legend_elements, loc='upper right')\n",
    "for text in legend.get_texts():\n",
    "    text.set_color('#352f36')  # Set legend label color\n",
    "\n",
    "# Remove top and right margin\n",
    "sns.despine(right=True, top=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disparity in distribution and proportion of our data suggests that our web scraping method may not be effective, as not all exhibition catalogues contain the word or similar terms in their title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Pubblication per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#publications per year in website\n",
    "# Get the count of each unique year\n",
    "count_series = pubblication_df_website['date'].value_counts()\n",
    "\n",
    "# Convert the Series to a DataFrame\n",
    "pubblication_per_year_website_df = count_series.reset_index()\n",
    "\n",
    "# Rename the columns to 'year' and 'count'\n",
    "pubblication_per_year_website_df.columns = ['date', 'count']\n",
    "\n",
    "# Sort the DataFrame by the 'year' column\n",
    "result_df = pubblication_per_year_website_df.sort_values(by='date')\n",
    "\n",
    "result_df.reset_index(drop=True, inplace=True)\n",
    "pubblication_per_year_website_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhibitions with catalogue per year\n",
    "\n",
    "# Drop rows where 'date' column has value 'Exh. cat'\n",
    "new_publication_df_website = pubblication_df_website[pubblication_df_website['type'] != 'Exh. cat.']\n",
    "new_publication_df_website\n",
    "\n",
    "# Get the count of each unique year\n",
    "count_series = new_publication_df_website['date'].value_counts()\n",
    "\n",
    "# Convert the Series to a DataFrame\n",
    "result_df_no_cat = count_series.reset_index()\n",
    "\n",
    "# Rename the columns to 'year' and 'count'\n",
    "result_df_no_cat.columns = ['date', 'count']\n",
    "\n",
    "# Sort the DataFrame by the 'year' column\n",
    "result_df_no_cat = result_df_no_cat.sort_values(by='date')\n",
    "\n",
    "result_df_no_cat\n",
    "\n",
    "result_df_no_cat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "result_df_no_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhibition in website per year\n",
    "# Concatenate 'startingdate' and 'endingdate' columns to create a single column containing all dates\n",
    "\n",
    "timeline_df = exhibition_df_website.copy()\n",
    "timeline_df['startingdate'] = pd.to_datetime(timeline_df['startingdate'])\n",
    "timeline_df['endingdate'] = pd.to_datetime(timeline_df['endingdate'])\n",
    "timeline_df['diff'] = timeline_df['endingdate'] - timeline_df['startingdate']\n",
    "\n",
    "all_dates = pd.concat([timeline_df['startingdate'], timeline_df['endingdate']])\n",
    "\n",
    "# Extract the year from each date\n",
    "all_years = pd.to_datetime(all_dates).dt.year\n",
    "\n",
    "# Count the occurrences of each year\n",
    "year_counts = all_years.value_counts().sort_index()\n",
    "\n",
    "# Convert year_counts Series to DataFrame\n",
    "year_counts_df = pd.DataFrame({'Year': year_counts.index, 'count': year_counts.values})\n",
    "\n",
    "\n",
    "\n",
    "year_counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Correlation ground truth\n",
    "**Research question**: Is there a correlation between publication and exhibition in our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare exhibition and pubblication \n",
    "import pandas as pd\n",
    "\n",
    "# Ensure 'date' column in df_1 is integer\n",
    "result_df_no_cat['date'] = result_df_no_cat['date'].astype(int)\n",
    "\n",
    "# Ensure 'Year' column in df_2 is integer\n",
    "year_counts_df['Year'] = year_counts_df['Year'].astype(int)\n",
    "\n",
    "# Merge the dataframes with suffixes\n",
    "merged_df_no_cat = pd.merge(result_df_no_cat, year_counts_df, how='outer', left_on='date', right_on='Year', suffixes=('_df1', '_df2'))\n",
    "\n",
    "# Substitute values in 'date' column with values from 'Year' column\n",
    "merged_df_no_cat['date'] = merged_df_no_cat['date'].fillna(merged_df_no_cat['Year'])\n",
    "\n",
    "# Convert the 'date' column back to integer type\n",
    "merged_df_no_cat['date'] = merged_df_no_cat['date'].astype(int)\n",
    "\n",
    "# Sort values based on date\n",
    "merged_df_no_cat.sort_values(by='date', inplace=True)\n",
    "\n",
    "# Drop the 'Year' column as it's no longer needed\n",
    "merged_df_no_cat.drop(columns=['Year'], inplace=True)\n",
    "\n",
    "merged_df_no_cat.fillna(0, inplace=True)\n",
    "\n",
    "merged_df_no_cat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line for count_df1\n",
    "plt.plot(merged_df_no_cat['date'], merged_df_no_cat['count_df1'], label='Publications', color='#B53302')\n",
    "\n",
    "# Plot line for count_df2\n",
    "plt.plot(merged_df_no_cat['date'], merged_df_no_cat['count_df2'], label='Exhibitions', color='#E97D01')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Year', color='#352f36')\n",
    "plt.ylabel('Count', color='#352f36')\n",
    "plt.title('Publications and Exhibitions - De Kooning Foundation', color='#352f36')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Remove top and right spines\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Change color of ticks\n",
    "plt.xticks(color='#352f36')\n",
    "plt.yticks(color='#352f36')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare exhibition and pubblication \n",
    "import pandas as pd\n",
    "\n",
    "# Ensure 'date' column in df_1 is integer\n",
    "result_df['date'] = result_df['date'].astype(int)\n",
    "\n",
    "# Ensure 'Year' column in df_2 is integer\n",
    "year_counts_df['Year'] = year_counts_df['Year'].astype(int)\n",
    "\n",
    "# Merge the dataframes with suffixes\n",
    "merged_df = pd.merge(result_df, year_counts_df, how='outer', left_on='date', right_on='Year', suffixes=('_df1', '_df2'))\n",
    "\n",
    "# Substitute values in 'date' column with values from 'Year' column\n",
    "merged_df['date'] = merged_df['date'].fillna(merged_df['Year'])\n",
    "\n",
    "# Convert the 'date' column back to integer type\n",
    "merged_df['date'] = merged_df['date'].astype(int)\n",
    "\n",
    "# Sort values based on date\n",
    "merged_df.sort_values(by='date', inplace=True)\n",
    "\n",
    "# Drop the 'Year' column as it's no longer needed\n",
    "merged_df.drop(columns=['Year'], inplace=True)\n",
    "\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. df auction data\n",
    "\n",
    "mean_price_per_year_dk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. df n of publication and exhibitions\n",
    "\n",
    "merged_df_no_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. merge df\n",
    "\n",
    "# Convert necessary columns to integers\n",
    "mean_price_per_year_dk_df['soldtime'] = mean_price_per_year_dk_df['soldtime'].astype(int)\n",
    "merged_df_no_cat['date'] = merged_df_no_cat['date'].astype(int)\n",
    "\n",
    "# Perform the merge\n",
    "merged_data = pd.merge(mean_price_per_year_dk_df, merged_df_no_cat, left_on='soldtime', right_on='date', how='left')\n",
    "merged_data = merged_data.drop(columns=['date'])\n",
    "\n",
    "# Fill NaN values with 0\n",
    "merged_data = merged_data.fillna(0)\n",
    "\n",
    "merged_data['count_df1_left'] = -merged_data['count_df1']\n",
    "merged_data['count_df2_left'] = 0\n",
    "\n",
    "merged_data\n",
    "\n",
    "\n",
    "# soldtime\tmean\tcount\tcount_df1\t              count_df2\t          count_df1_left\tcount_df2_left\n",
    "# Age\t                    Male, Male_Width       Female,Female_Width       Male_Left              Female_Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Assuming df is your DataFrame with the columns mentioned\n",
    "# df = your_dataframe_here\n",
    "\n",
    "# Create a custom colormap based on the 'mean' values\n",
    "colors_1 = ['#FEDB9B', '#F4C385', '#E9AB6F', '#DF9359', '#D47B44', '#CA632E', '#BF4B18', '#B53302'] # Define colors for the gradient\n",
    "cmap_1 = LinearSegmentedColormap.from_list('custom_cmap_1', colors_1)\n",
    "\n",
    "colors_2 = ['#FFCCD5', '#E7B1BB', '#D095A2', '#B87A88', '#A05F6F', '#884455', '#71283C', '#590D22']\n",
    "cmap_2 = LinearSegmentedColormap.from_list('custom_cmap_2', colors_2)\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Iterate through each data point\n",
    "for i, sold_time in enumerate(merged_data['soldtime']):\n",
    "    # Get the mean value for the current sold time\n",
    "    mean_value = merged_data.loc[i, 'mean']\n",
    "    # Get the color from the color_map\n",
    "    color_1 = colors_1[i]  # Using predefined colors directly\n",
    "    color_2 = colors_2[i]  # Using predefined colors directly\n",
    "    # Plot count_df1\n",
    "    bar1 = plt.bar(sold_time, merged_data.loc[i, 'count_df1'], width=bar_width, alpha=0.7, label='count_df1', color=color_1)\n",
    "    \n",
    "    # Plot count_df2 next to count_df1 with an additional offset for space\n",
    "    bar2 = plt.bar(sold_time + bar_width + 0.1, merged_data.loc[i, 'count_df2'], width=bar_width, alpha=0.7, label='count_df2', color=color_2)\n",
    "\n",
    "# Create ScalarMappable objects for colormap\n",
    "sm_1 = ScalarMappable(cmap=cmap_1)\n",
    "sm_1.set_array(merged_data['mean'])  # Set the range of values for the colormap\n",
    "\n",
    "sm_2 = ScalarMappable(cmap=cmap_2)\n",
    "sm_2.set_array(merged_data['mean'])  # Set the range of values for the colormap\n",
    "\n",
    "# Add colorbars\n",
    "cbar_1 = plt.colorbar(sm_1, ax=plt.gca())\n",
    "cbar_1.set_label('Publication Mean - in mln')\n",
    "\n",
    "cbar_2 = plt.colorbar(sm_2, ax=plt.gca())\n",
    "cbar_2.set_label('Exhibition Mean - in mln')\n",
    "\n",
    "# Define function to format tick labels\n",
    "def format_millions(x, pos):\n",
    "    'The two args are the value and tick position'\n",
    "    return '{:.1f}'.format(x * 1e-6)  # Format with one decimal place for millions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set formatter for colorbar tick labels to display numbers in millions\n",
    "cbar_1.ax.yaxis.set_major_formatter(FuncFormatter(format_millions))\n",
    "cbar_2.ax.yaxis.set_major_formatter(FuncFormatter(format_millions))\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Chart of Publications and Exhibitions per mean of price in year')\n",
    "\n",
    "# Adjust x-axis ticks if necessary\n",
    "plt.xticks(merged_data['soldtime'] + bar_width / 2, merged_data['soldtime'])\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Our conclusions indicate that there is no correlation between publication, exhibition, and auctions based on our data analysis. Possible reasons for this could include:\n",
    "- Insufficient data: The analysis may have been conducted with an inadequate amount of data. Both quantitative and qualitative data in larger quantities may be required to draw more accurate conclusions.\n",
    "- Incorrect variables: It's possible that the variables chosen for analysis are not the most appropriate for measuring reputation in the art world. Reconsidering the selection of variables may be necessary.\n",
    "- Lack of actual correlation: even if the chosen variables are correct, it's plausible that there simply isn't a significant correlation between publication, exhibition, and auction success in terms of an artist's reputation. This suggests that these aspects of an artist's career may operate independently of each other when it comes to determining reputation.\n",
    "\n",
    "Other parameters that could have been taken into consideration are:\n",
    "- Buyers and sellers in the auction records if they’re contained in the original dataset.\n",
    "- The art historians that have talked about the artist and if they have influenced the other variables in some way\n",
    "- Venues in which the artworks are present, in particular considering also the prestige of the venue. \n",
    "- Expand the research considering scientific articles and not only monographs or exhibition catalogues. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
